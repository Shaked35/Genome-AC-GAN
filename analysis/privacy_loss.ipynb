{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Compute accuracy\n",
    "\"\"\"\n",
    "import concurrent.futures\n",
    "import os\n",
    "import pickle as pkl\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Scores():\n",
    "    \"\"\"\n",
    "    Calculates various scoring metrics amongst training, testing and synthetic data files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_file : string, required\n",
    "        The training file to be used.\n",
    "    test_file : string, required\n",
    "        The test file to be used.\n",
    "    synthetic_file: list, required\n",
    "        The list of various synthetic data files to be used.\n",
    "    dist_file: string, optional\n",
    "        The file that containts previously computed distances to omit recalculation.\n",
    "    workers: int, optional\n",
    "        The count of workers to use with the default value of 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_file, test_file, synthetic_files, dist_file=None, workers=1, n_neighbors=5, leaf_size=30):\n",
    "        \"\"\"\n",
    "        Collect all training, testing and synthetic data files for processing\n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.leaf_size = leaf_size\n",
    "        training_data = pd.read_csv(train_file)\n",
    "        training_data = training_data.fillna(training_data.mean())\n",
    "\n",
    "        testing_data = pd.read_csv(test_file)\n",
    "        testing_data = testing_data.fillna(testing_data.mean())\n",
    "\n",
    "        self.data = {\n",
    "            \"training_data\": training_data,\n",
    "            \"testing_data\": testing_data\n",
    "        }\n",
    "\n",
    "        self.synth_keys = []\n",
    "        for i, s in enumerate(synthetic_files):\n",
    "            self.data[f'synth_{i}'] = np.clip(pd.read_csv(s), 0, 1)\n",
    "            self.synth_keys.append(f'synth_{i}')\n",
    "\n",
    "        self.distances = {}\n",
    "\n",
    "        if dist_file is not None:\n",
    "            self.distances = pkl.load(open(dist_file, 'rb'))\n",
    "        else:\n",
    "            self.__compute_nn(workers)\n",
    "\n",
    "    def __nearest_neighbors(self, t, s):\n",
    "        # Fit to S\n",
    "        nn_s = NearestNeighbors(n_neighbors=self.n_neighbors, leaf_size=self.leaf_size).fit(self.data[s])\n",
    "        if t == s:\n",
    "            # Find distances from s to s\n",
    "            d = nn_s.kneighbors()[0]\n",
    "        else:\n",
    "            # Find distances from t to s\n",
    "            d = nn_s.kneighbors(self.data[t])[0]\n",
    "        return t, s, d\n",
    "\n",
    "    def __compute_nn(self, workers):\n",
    "        tasks = product(self.data.keys(), repeat=2)\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "            futures = [\n",
    "                executor.submit(self.__nearest_neighbors, t, s)\n",
    "                for (t, s) in tasks\n",
    "            ]\n",
    "\n",
    "            # Wait for each job to finish\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures),\n",
    "                               total=len(futures)):\n",
    "                t, s, d = future.result()\n",
    "                self.distances[(t, s)] = d\n",
    "\n",
    "        if not os.path.isdir(\"gen_data\"):\n",
    "            os.mkdir(\"gen_data\")\n",
    "\n",
    "        pkl.dump(self.distances, open(f'gen_data/syn_dists.pkl', 'wb'))\n",
    "\n",
    "    def __discrepancy_score(self, t, s):\n",
    "        left = np.mean(self.distances[(t, s)])\n",
    "        right = np.mean(self.distances[(s, t)])\n",
    "        return 0.5 * (left + right)\n",
    "\n",
    "    def compute_discrepancy(self):\n",
    "        \"\"\"\n",
    "        Compute the standard discrepancy scores\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        The discrepency amongst the various data files.\n",
    "        \"\"\"\n",
    "        j_rr = self.__discrepancy_score('training_data', 'testing_data')\n",
    "        j_ra = []\n",
    "        j_rat = []\n",
    "        j_aa = []\n",
    "\n",
    "        # For all of the synthetic datasets\n",
    "        for k in self.synth_keys:\n",
    "            j_ra.append(self.__discrepancy_score('training_data', k))\n",
    "            j_rat.append(self.__discrepancy_score('testing_data', k))\n",
    "            # Comparison to other synthetics\n",
    "            for k_2 in self.synth_keys:\n",
    "                if k != k_2:\n",
    "                    j_aa.append(self.__discrepancy_score(k, k_2))\n",
    "\n",
    "        # Average across synthetics\n",
    "        j_ra = np.mean(np.array(j_ra))\n",
    "        j_rat = np.mean(np.array(j_rat))\n",
    "        j_aa = np.mean(np.array(j_aa))\n",
    "\n",
    "        discrepancy_training_test = np.round(j_rr, 4)\n",
    "        discrepancy_training_synthetic = np.round(j_ra, 4)\n",
    "        discrepancy_test_synthetic = np.round(j_rat, 4)\n",
    "        discrepancy_synthetic = np.round(j_aa, 4)\n",
    "        print(\"Discrepancy in training and test data is: {}\".format(discrepancy_training_test))\n",
    "        print(\"Discrepancy in training data and synthetic data is: {}\".format(discrepancy_training_synthetic))\n",
    "        print(\"Discrepancy in testing and synthetic data is: {}\".format(discrepancy_test_synthetic))\n",
    "        print(\"Discrepancy amongst various synthetic data files is: {}\".format(discrepancy_synthetic))\n",
    "        return discrepancy_training_test, discrepancy_training_synthetic, discrepancy_test_synthetic, discrepancy_synthetic\n",
    "\n",
    "    def __divergence(self, t, s):\n",
    "        left = np.mean(np.log(self.distances[(t, s)] / self.distances[(t, t)]))\n",
    "        right = np.mean(np.log(self.distances[(s, t)] / self.distances[(s, s)]))\n",
    "        return 0.5 * (left + right)\n",
    "\n",
    "    def compute_divergence(self):\n",
    "        \"\"\"\n",
    "        Compute the divergence scores\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        The divergence score amongst the various data files.\n",
    "        \"\"\"\n",
    "        d_tr_a = []\n",
    "        d_te_a = []\n",
    "\n",
    "        for k in self.synth_keys:\n",
    "            d_tr_a.append(self.__divergence('training_data', k))\n",
    "            d_te_a.append(self.__divergence('testing_data', k))\n",
    "\n",
    "        training = np.mean(np.array(d_tr_a))\n",
    "        testing = np.mean(np.array(d_te_a))\n",
    "\n",
    "        divergence_training = np.round(training, 4)\n",
    "        divergence_test = np.round(testing, 4)\n",
    "        print(\"Divergence in training and synthetic data is: {}\".format(divergence_training))\n",
    "        print(\"Divergence in testing and synthetic data is: {}\".format(divergence_test))\n",
    "        return divergence_training, divergence_test\n",
    "\n",
    "    def __adversarial_accuracy(self, t, s):\n",
    "        left = np.mean(self.distances[(t, s)] > self.distances[(t, t)])\n",
    "        right = np.mean(self.distances[(s, t)] > self.distances[(s, s)])\n",
    "        return 0.5 * (left + right)\n",
    "\n",
    "    def __calculate_accuracy(self):\n",
    "        \"\"\"\n",
    "        Compute the standarad adversarial accuracy scores\n",
    "        \"\"\"\n",
    "\n",
    "        train_accuracy = []\n",
    "        test_accuracy = []\n",
    "        for key in self.synth_keys:\n",
    "            train_accuracy.append(self.__adversarial_accuracy('training_data', key))\n",
    "            test_accuracy.append(self.__adversarial_accuracy('testing_data', key))\n",
    "\n",
    "        avg_train_accuracy = np.mean(np.array(train_accuracy))\n",
    "        avg_test_accuracy = np.mean(np.array(test_accuracy))\n",
    "        return avg_train_accuracy, avg_test_accuracy\n",
    "\n",
    "    def calculate_accuracy(self):\n",
    "        \"\"\"\n",
    "        Compute the standarad adversarial accuracy scores\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        The adversarial accuracy for the two data files along with privacy loss.\n",
    "        \"\"\"\n",
    "\n",
    "        train_acc, test_acc = self.__calculate_accuracy()\n",
    "        TrainResemblanceLoss = np.round(train_acc, 4)\n",
    "        TestResemblanceLoss = np.round(test_acc, 4)\n",
    "        PrivacyLoss = np.round(np.round(test_acc, 4) - np.round(train_acc, 4), 4)\n",
    "        print(\"Adversarial accuracy for train data is: {}\".format(TrainResemblanceLoss))\n",
    "        print(\"Adversarial accuracy for test data is: {}\".format(TestResemblanceLoss))\n",
    "        print(\"Privacy Loss is: {}\".format(PrivacyLoss))\n",
    "        return TrainResemblanceLoss, TestResemblanceLoss, PrivacyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class MemInfPlot():\n",
    "    \"\"\"\n",
    "    Uses `matplotlib` and `seaborn` to plot the membership inference plot\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_file : string, required\n",
    "        The training file to be used for generating the membership inference plot.\n",
    "    test_file : string, required\n",
    "        The testing file to be used for generating the membership inference plot.\n",
    "    synth_file : string, required\n",
    "        The synthetic data file to be used for generating the membership inference plot.\n",
    "    name : string, required\n",
    "        A name for the plot.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_file, test_file, synth_file, name):\n",
    "\n",
    "        if not os.path.exists('gen_data'):\n",
    "            os.makedirs('gen_data')\n",
    "\n",
    "        if not os.path.exists('gen_data/plots'):\n",
    "            os.makedirs('gen_data/plots')\n",
    "\n",
    "        data, labels = self.__create_shuffled_data(train_file, test_file)\n",
    "        self.fpr, self.tpr, self.auc = self.__compute_auc(synth_file, data, labels)\n",
    "        self.name = name\n",
    "\n",
    "        print(\"AUC = {}\".format(self.auc))\n",
    "\n",
    "    def __create_shuffled_data(self, train_file, test_file):\n",
    "\n",
    "        # Read in train and test\n",
    "        train_set = pd.read_csv(train_file)\n",
    "        test_set = pd.read_csv(test_file)\n",
    "\n",
    "        # Create labels\n",
    "        label_train = np.empty(train_set.shape[0], dtype=int)\n",
    "        label_train.fill(-1)\n",
    "        label_test = np.empty(test_set.shape[0], dtype=int)\n",
    "        label_test.fill(1)\n",
    "\n",
    "        # Combine\n",
    "        labels = np.concatenate([label_train, label_test], axis=0)\n",
    "        data = pd.concat([train_set, test_set], axis=0)\n",
    "        data['labels'] = labels.tolist()\n",
    "\n",
    "        # Randomize\n",
    "        data = shuffle(data)\n",
    "        data, labels = (data.drop('labels', axis=1), data['labels'])\n",
    "\n",
    "        return data, labels\n",
    "\n",
    "    def __compute_auc(self, synth_file, data, labels):\n",
    "\n",
    "        synth_data = pd.read_csv(synth_file)\n",
    "\n",
    "        syn_dists = self.__nearest_neighbors(data, synth_data)\n",
    "        fpr, tpr, _ = metrics.roc_curve(labels.ravel(), syn_dists)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        return fpr, tpr, roc_auc\n",
    "\n",
    "    def __nearest_neighbors(self, t, s):\n",
    "        \"\"\"\n",
    "        Find nearest neighbors d_ts and d_ss\n",
    "        \"\"\"\n",
    "\n",
    "        # Fit to S\n",
    "        nn_s = NearestNeighbors().fit(s)\n",
    "\n",
    "        # Find distances from t to s\n",
    "        d = nn_s.kneighbors(t)[0]\n",
    "\n",
    "        return d\n",
    "\n",
    "    def plot(self, savefig=False):\n",
    "        \"\"\"\n",
    "        The function plots the membership inference plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        savefig: boolean, optional\n",
    "            If set to True, the plots generated will be saved to disk.\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        PCA Plot:\n",
    "            Plots the AUC curve and saves the file as\n",
    "            `membership_inference_auc_{name}.png`\n",
    "        \"\"\"\n",
    "\n",
    "        pylab.rcParams['figure.figsize'] = 6, 6\n",
    "        plt.title('Receiver Operating Characteristic', fontsize=24)\n",
    "        plt.plot([0, 1], [0, 1], 'r--')\n",
    "        plt.plot(self.fpr, self.tpr, label=f'{self.name} AUC = {self.auc:0.2f}')\n",
    "\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.ylabel('True Positive Rate', fontsize=18)\n",
    "        plt.xlabel('False Positive Rate', fontsize=18)\n",
    "\n",
    "        if (savefig):\n",
    "            plt.savefig(f'gen_data/membership_inference_auc_{self.name}.png')\n",
    "        plt.show()\n",
    "        if (savefig):\n",
    "            print(f\"The plot has been saved as membership_inference_auc_{self.name}.png inside gen_data/plots.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "synthetics = {\"real_train\": \"clean_train_0.8.csv\", \"real_copy_all\": \"clean_10k_real.csv\",\n",
    "              \"augmented_real_train_data\": \"augmented_real_data.csv\", \"random\": \"random_data.csv\",\n",
    "              \"Genome-AC-GAN 80%\": \"clean_polyloss_ce.csv\", \"Genome-AC-GAN super pop\": \"clean_full_pop.csv\",\n",
    "              \"Genome-AC-GAN sub pop\": \"clean_full_sub_pop.csv\", \"RBM new\": \"clean_rbm_new.csv\",\n",
    "              \"RBM old\": \"clean_old_rbm.csv\", \"WGAN\": \"clean_WGAN.csv\"}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start real_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.86s/it]\n",
      "/var/folders/gg/cdx7t5lx167_frdvqm0mxt5c0000gn/T/ipykernel_86359/2756800775.py:141: RuntimeWarning: divide by zero encountered in log\n",
      "  left = np.mean(np.log(self.distances[(t, s)] / self.distances[(t, t)]))\n",
      "/var/folders/gg/cdx7t5lx167_frdvqm0mxt5c0000gn/T/ipykernel_86359/2756800775.py:142: RuntimeWarning: divide by zero encountered in log\n",
      "  right = np.mean(np.log(self.distances[(s, t)] / self.distances[(s, s)]))\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.0\n",
      "Adversarial accuracy for test data is: 0.4987\n",
      "Privacy Loss is: 0.4987\n",
      "Divergence in training and synthetic data is: -inf\n",
      "Divergence in testing and synthetic data is: 0.0005\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 17.6286\n",
      "Discrepancy in testing and synthetic data is: 27.8641\n",
      "Discrepancy amongst various synthetic data files is: nan\n",
      "start real_copy_all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.84s/it]\n",
      "/var/folders/gg/cdx7t5lx167_frdvqm0mxt5c0000gn/T/ipykernel_86359/2756800775.py:141: RuntimeWarning: divide by zero encountered in log\n",
      "  left = np.mean(np.log(self.distances[(t, s)] / self.distances[(t, t)]))\n",
      "/var/folders/gg/cdx7t5lx167_frdvqm0mxt5c0000gn/T/ipykernel_86359/2756800775.py:142: RuntimeWarning: divide by zero encountered in log\n",
      "  right = np.mean(np.log(self.distances[(s, t)] / self.distances[(s, s)]))\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.0727\n",
      "Adversarial accuracy for test data is: 0.4061\n",
      "Privacy Loss is: 0.3334\n",
      "Divergence in training and synthetic data is: -inf\n",
      "Divergence in testing and synthetic data is: -inf\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 19.5079\n",
      "Discrepancy in testing and synthetic data is: 23.0524\n",
      "Discrepancy amongst various synthetic data files is: nan\n",
      "start augmented_real_train_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:10<00:00,  1.18s/it]\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.4999\n",
      "Adversarial accuracy for test data is: 0.486\n",
      "Privacy Loss is: -0.0139\n",
      "Divergence in training and synthetic data is: 0.1181\n",
      "Divergence in testing and synthetic data is: 0.02\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 38.1205\n",
      "Discrepancy in testing and synthetic data is: 36.1029\n",
      "Discrepancy amongst various synthetic data files is: nan\n",
      "start random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:13<00:00,  1.53s/it]\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.9583\n",
      "Adversarial accuracy for test data is: 0.9742\n",
      "Privacy Loss is: 0.0159\n",
      "Divergence in training and synthetic data is: 0.4881\n",
      "Divergence in testing and synthetic data is: 0.4486\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 69.864\n",
      "Discrepancy in testing and synthetic data is: 69.8965\n",
      "Discrepancy amongst various synthetic data files is: nan\n",
      "start Genome-AC-GAN 80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.82s/it]\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.645\n",
      "Adversarial accuracy for test data is: 0.5684\n",
      "Privacy Loss is: -0.0766\n",
      "Divergence in training and synthetic data is: 0.0387\n",
      "Divergence in testing and synthetic data is: 0.0358\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 27.0489\n",
      "Discrepancy in testing and synthetic data is: 28.0287\n",
      "Discrepancy amongst various synthetic data files is: nan\n",
      "start Genome-AC-GAN super pop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:18<00:00,  2.09s/it]\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.6549\n",
      "Adversarial accuracy for test data is: 0.5447\n",
      "Privacy Loss is: -0.1102\n",
      "Divergence in training and synthetic data is: 0.0579\n",
      "Divergence in testing and synthetic data is: 0.0447\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 26.6331\n",
      "Discrepancy in testing and synthetic data is: 27.3342\n",
      "Discrepancy amongst various synthetic data files is: nan\n",
      "start Genome-AC-GAN sub pop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:18<00:00,  2.04s/it]\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.6588\n",
      "Adversarial accuracy for test data is: 0.5483\n",
      "Privacy Loss is: -0.1105\n",
      "Divergence in training and synthetic data is: 0.0428\n",
      "Divergence in testing and synthetic data is: 0.0293\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 27.1304\n",
      "Discrepancy in testing and synthetic data is: 27.8469\n",
      "Discrepancy amongst various synthetic data files is: nan\n",
      "start RBM new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:18<00:00,  2.10s/it]\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.6965\n",
      "Adversarial accuracy for test data is: 0.653\n",
      "Privacy Loss is: -0.0435\n",
      "Divergence in training and synthetic data is: 0.0487\n",
      "Divergence in testing and synthetic data is: 0.0544\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 27.4124\n",
      "Discrepancy in testing and synthetic data is: 28.6122\n",
      "Discrepancy amongst various synthetic data files is: nan\n",
      "start RBM old\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:20<00:00,  2.32s/it]\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.4651\n",
      "Adversarial accuracy for test data is: 0.4917\n",
      "Privacy Loss is: 0.0266\n",
      "Divergence in training and synthetic data is: 0.0077\n",
      "Divergence in testing and synthetic data is: -0.0025\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 27.0325\n",
      "Discrepancy in testing and synthetic data is: 27.8353\n",
      "Discrepancy amongst various synthetic data files is: nan\n",
      "start WGAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:19<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy for train data is: 0.811\n",
      "Adversarial accuracy for test data is: 0.6545\n",
      "Privacy Loss is: -0.1565\n",
      "Divergence in training and synthetic data is: 0.0667\n",
      "Divergence in testing and synthetic data is: 0.0483\n",
      "Discrepancy in training and test data is: 27.8641\n",
      "Discrepancy in training data and synthetic data is: 28.2856\n",
      "Discrepancy in testing and synthetic data is: 28.8955\n",
      "Discrepancy amongst various synthetic data files is: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shakedahronoviz/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for model_name, file_path in synthetics.items():\n",
    "    print(f\"start {model_name}\")\n",
    "    s = Scores(train_file=\"clean_train_0.8.csv\", test_file=\"clean_test_0.2.csv\",\n",
    "               synthetic_files=[file_path], n_neighbors=3, leaf_size=10)\n",
    "    TrainResemblanceLoss, TestResemblanceLoss, PrivacyLoss = s.calculate_accuracy()\n",
    "    divergence_training, divergence_test = s.compute_divergence()\n",
    "    discrepancy_training_test, discrepancy_training_synthetic, discrepancy_test_synthetic, discrepancy_synthetic = s.compute_discrepancy()\n",
    "    rows.append(\n",
    "        {\"model_name\": model_name, \"TrainResemblanceLoss\": TrainResemblanceLoss,\n",
    "         \"TestResemblanceLoss\": TestResemblanceLoss, \"PrivacyLoss\": PrivacyLoss,\n",
    "         \"divergence_training\": divergence_training, \"divergence_test\": divergence_test,\n",
    "         \"discrepancy_training_test\": discrepancy_training_test,\n",
    "         \"discrepancy_training_synthetic\": discrepancy_training_synthetic,\n",
    "         \"discrepancy_test_synthetic\": discrepancy_test_synthetic})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                  model_name  TrainResemblanceLoss  TestResemblanceLoss   \n0                 real_train                0.0000               0.4987  \\\n1              real_copy_all                0.0727               0.4061   \n2  augmented_real_train_data                0.4999               0.4860   \n3                     random                0.9583               0.9742   \n4          Genome-AC-GAN 80%                0.6450               0.5684   \n5    Genome-AC-GAN super pop                0.6549               0.5447   \n6      Genome-AC-GAN sub pop                0.6588               0.5483   \n7                    RBM new                0.6965               0.6530   \n8                    RBM old                0.4651               0.4917   \n9                       WGAN                0.8110               0.6545   \n\n   PrivacyLoss  divergence_training  divergence_test   \n0       0.4987                 -inf           0.0005  \\\n1       0.3334                 -inf             -inf   \n2      -0.0139               0.1181           0.0200   \n3       0.0159               0.4881           0.4486   \n4      -0.0766               0.0387           0.0358   \n5      -0.1102               0.0579           0.0447   \n6      -0.1105               0.0428           0.0293   \n7      -0.0435               0.0487           0.0544   \n8       0.0266               0.0077          -0.0025   \n9      -0.1565               0.0667           0.0483   \n\n   discrepancy_training_test  discrepancy_training_synthetic   \n0                    27.8641                         17.6286  \\\n1                    27.8641                         19.5079   \n2                    27.8641                         38.1205   \n3                    27.8641                         69.8640   \n4                    27.8641                         27.0489   \n5                    27.8641                         26.6331   \n6                    27.8641                         27.1304   \n7                    27.8641                         27.4124   \n8                    27.8641                         27.0325   \n9                    27.8641                         28.2856   \n\n   discrepancy_test_synthetic  \n0                     27.8641  \n1                     23.0524  \n2                     36.1029  \n3                     69.8965  \n4                     28.0287  \n5                     27.3342  \n6                     27.8469  \n7                     28.6122  \n8                     27.8353  \n9                     28.8955  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_name</th>\n      <th>TrainResemblanceLoss</th>\n      <th>TestResemblanceLoss</th>\n      <th>PrivacyLoss</th>\n      <th>divergence_training</th>\n      <th>divergence_test</th>\n      <th>discrepancy_training_test</th>\n      <th>discrepancy_training_synthetic</th>\n      <th>discrepancy_test_synthetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>real_train</td>\n      <td>0.0000</td>\n      <td>0.4987</td>\n      <td>0.4987</td>\n      <td>-inf</td>\n      <td>0.0005</td>\n      <td>27.8641</td>\n      <td>17.6286</td>\n      <td>27.8641</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>real_copy_all</td>\n      <td>0.0727</td>\n      <td>0.4061</td>\n      <td>0.3334</td>\n      <td>-inf</td>\n      <td>-inf</td>\n      <td>27.8641</td>\n      <td>19.5079</td>\n      <td>23.0524</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>augmented_real_train_data</td>\n      <td>0.4999</td>\n      <td>0.4860</td>\n      <td>-0.0139</td>\n      <td>0.1181</td>\n      <td>0.0200</td>\n      <td>27.8641</td>\n      <td>38.1205</td>\n      <td>36.1029</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>random</td>\n      <td>0.9583</td>\n      <td>0.9742</td>\n      <td>0.0159</td>\n      <td>0.4881</td>\n      <td>0.4486</td>\n      <td>27.8641</td>\n      <td>69.8640</td>\n      <td>69.8965</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Genome-AC-GAN 80%</td>\n      <td>0.6450</td>\n      <td>0.5684</td>\n      <td>-0.0766</td>\n      <td>0.0387</td>\n      <td>0.0358</td>\n      <td>27.8641</td>\n      <td>27.0489</td>\n      <td>28.0287</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Genome-AC-GAN super pop</td>\n      <td>0.6549</td>\n      <td>0.5447</td>\n      <td>-0.1102</td>\n      <td>0.0579</td>\n      <td>0.0447</td>\n      <td>27.8641</td>\n      <td>26.6331</td>\n      <td>27.3342</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Genome-AC-GAN sub pop</td>\n      <td>0.6588</td>\n      <td>0.5483</td>\n      <td>-0.1105</td>\n      <td>0.0428</td>\n      <td>0.0293</td>\n      <td>27.8641</td>\n      <td>27.1304</td>\n      <td>27.8469</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RBM new</td>\n      <td>0.6965</td>\n      <td>0.6530</td>\n      <td>-0.0435</td>\n      <td>0.0487</td>\n      <td>0.0544</td>\n      <td>27.8641</td>\n      <td>27.4124</td>\n      <td>28.6122</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RBM old</td>\n      <td>0.4651</td>\n      <td>0.4917</td>\n      <td>0.0266</td>\n      <td>0.0077</td>\n      <td>-0.0025</td>\n      <td>27.8641</td>\n      <td>27.0325</td>\n      <td>27.8353</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>WGAN</td>\n      <td>0.8110</td>\n      <td>0.6545</td>\n      <td>-0.1565</td>\n      <td>0.0667</td>\n      <td>0.0483</td>\n      <td>27.8641</td>\n      <td>28.2856</td>\n      <td>28.8955</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(rows)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start real_train\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (5008, 5) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_name, file_path \u001B[38;5;129;01min\u001B[39;00m synthetics\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m     m \u001B[38;5;241m=\u001B[39m \u001B[43mMemInfPlot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mclean_train_0.8.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mclean_test_0.2.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msynth_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     m\u001B[38;5;241m.\u001B[39mplot()\n",
      "Cell \u001B[0;32mIn[10], line 26\u001B[0m, in \u001B[0;36mMemInfPlot.__init__\u001B[0;34m(self, train_file, test_file, synth_file, name)\u001B[0m\n\u001B[1;32m     23\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgen_data/plots\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     25\u001B[0m data, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__create_shuffled_data(train_file, test_file)\n\u001B[0;32m---> 26\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfpr, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtpr, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__compute_auc\u001B[49m\u001B[43m(\u001B[49m\u001B[43msynth_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m=\u001B[39m name\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAUC = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauc))\n",
      "Cell \u001B[0;32mIn[10], line 59\u001B[0m, in \u001B[0;36mMemInfPlot.__compute_auc\u001B[0;34m(self, synth_file, data, labels)\u001B[0m\n\u001B[1;32m     56\u001B[0m synth_data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(synth_file)\n\u001B[1;32m     58\u001B[0m syn_dists \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__nearest_neighbors(data, synth_data)\n\u001B[0;32m---> 59\u001B[0m fpr, tpr, _ \u001B[38;5;241m=\u001B[39m \u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroc_curve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msyn_dists\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m roc_auc \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39mauc(fpr, tpr)\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fpr, tpr, roc_auc\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:992\u001B[0m, in \u001B[0;36mroc_curve\u001B[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001B[0m\n\u001B[1;32m    904\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mroc_curve\u001B[39m(\n\u001B[1;32m    905\u001B[0m     y_true, y_score, \u001B[38;5;241m*\u001B[39m, pos_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, drop_intermediate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    906\u001B[0m ):\n\u001B[1;32m    907\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001B[39;00m\n\u001B[1;32m    908\u001B[0m \n\u001B[1;32m    909\u001B[0m \u001B[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    990\u001B[0m \u001B[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001B[39;00m\n\u001B[1;32m    991\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 992\u001B[0m     fps, tps, thresholds \u001B[38;5;241m=\u001B[39m \u001B[43m_binary_clf_curve\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    993\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\n\u001B[1;32m    994\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    996\u001B[0m     \u001B[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001B[39;00m\n\u001B[1;32m    997\u001B[0m     \u001B[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001B[39;00m\n\u001B[1;32m    998\u001B[0m     \u001B[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1003\u001B[0m     \u001B[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001B[39;00m\n\u001B[1;32m   1004\u001B[0m     \u001B[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001B[39;00m\n\u001B[1;32m   1005\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drop_intermediate \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fps) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:753\u001B[0m, in \u001B[0;36m_binary_clf_curve\u001B[0;34m(y_true, y_score, pos_label, sample_weight)\u001B[0m\n\u001B[1;32m    751\u001B[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001B[1;32m    752\u001B[0m y_true \u001B[38;5;241m=\u001B[39m column_or_1d(y_true)\n\u001B[0;32m--> 753\u001B[0m y_score \u001B[38;5;241m=\u001B[39m \u001B[43mcolumn_or_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    754\u001B[0m assert_all_finite(y_true)\n\u001B[1;32m    755\u001B[0m assert_all_finite(y_score)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow_27/lib/python3.9/site-packages/sklearn/utils/validation.py:1202\u001B[0m, in \u001B[0;36mcolumn_or_1d\u001B[0;34m(y, dtype, warn)\u001B[0m\n\u001B[1;32m   1193\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1194\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA column-vector y was passed when a 1d array was\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1195\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m expected. Please change the shape of y to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1198\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m   1199\u001B[0m         )\n\u001B[1;32m   1200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _asarray_with_order(xp\u001B[38;5;241m.\u001B[39mreshape(y, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m), order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m\"\u001B[39m, xp\u001B[38;5;241m=\u001B[39mxp)\n\u001B[0;32m-> 1202\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1203\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my should be a 1d array, got an array of shape \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shape)\n\u001B[1;32m   1204\u001B[0m )\n",
      "\u001B[0;31mValueError\u001B[0m: y should be a 1d array, got an array of shape (5008, 5) instead."
     ]
    }
   ],
   "source": [
    "for model_name, file_path in synthetics.items():\n",
    "    print(f\"start {model_name}\")\n",
    "    m = MemInfPlot(train_file=\"clean_train_0.8.csv\", test_file=\"clean_test_0.2.csv\", synth_file=file_path,\n",
    "                   name=model_name)\n",
    "    m.plot()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from utils.util import get_relevant_columns\n",
    "# import pandas as pd\n",
    "#\n",
    "# file_path = \"/Users/shakedahronoviz/Genome-AC-GAN/resource/train_0.8_super_pop.csv\"\n",
    "# model_sequences = pd.read_csv(file_path)\n",
    "# columns = get_relevant_columns(model_sequences, model_sequences.columns[:2])\n",
    "# model_sequences = model_sequences[columns]\n",
    "# columns = [int(i) for i in columns]\n",
    "# model_sequences.columns = columns\n",
    "# number_of_samples = len(model_sequences)\n",
    "# model_sequences[0] = \"model_name\"\n",
    "# x = pd.DataFrame({'label': model_sequences[0], 'ind': model_sequences[1]})\n",
    "# train = pd.DataFrame(np.array(model_sequences.loc[:, 2:].astype(int)))\n",
    "#\n",
    "# file_path = \"/Users/shakedahronoviz/Genome-AC-GAN/resource/test_0.2_super_pop.csv\"\n",
    "# model_sequences = pd.read_csv(file_path)\n",
    "# columns = get_relevant_columns(model_sequences, model_sequences.columns[:2])\n",
    "# model_sequences = model_sequences[columns]\n",
    "# columns = [int(i) for i in columns]\n",
    "# model_sequences.columns = columns\n",
    "# number_of_samples = len(model_sequences)\n",
    "# model_sequences[0] = \"model_name\"\n",
    "# x = pd.DataFrame({'label': model_sequences[0], 'ind': model_sequences[1]})\n",
    "# test = pd.DataFrame(np.array(model_sequences.loc[:, 2:].astype(int)))\n",
    "#\n",
    "# pd.concat([train, test]).to_csv(\"train_and_\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# file_path = \"/Users/shakedahronoviz/Genome-AC-GAN/fake_genotypes_sequences/new_sequences/polyloss_ce/genotypes.hapt\"\n",
    "# model_sequences = pd.read_csv(file_path, sep=' ', header=None)\n",
    "# model_sequences.columns = [column if column == 0 else column + 1 for column in model_sequences.columns]\n",
    "# model_sequences.insert(0, 1, [f\"AG{sample_id}\" for sample_id in range(model_sequences.shape[0])])\n",
    "# model_sequences[0] = \"model_name\"\n",
    "# x = pd.DataFrame({'label': model_sequences[0], 'ind': model_sequences[1]})\n",
    "# pd.DataFrame(np.array(model_sequences.loc[:, 2:].astype(int))).to_csv(\"clean_polyloss_ce.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# file_path = \"/Users/shakedahronoviz/Genome-AC-GAN/resource/10K_SNP_1000G_real.hapt\"\n",
    "# model_sequences = pd.read_csv(file_path, sep=' ', header=None)\n",
    "# if model_sequences.shape[1] == 808:  # special case for a specific file that had an extra empty column\n",
    "#     model_sequences = model_sequences.drop(columns=model_sequences.columns[-1])\n",
    "# if model_sequences.shape[0] > number_of_samples:\n",
    "#     model_sequences = model_sequences.drop(\n",
    "#         index=np.sort(\n",
    "#             np.random.choice(np.arange(model_sequences.shape[0]),\n",
    "#                              size=model_sequences.shape[0] - number_of_samples,\n",
    "#                              replace=False)))\n",
    "# model_sequences[0] = \"model_name\"\n",
    "# x = pd.DataFrame({'label': model_sequences[0], 'ind': model_sequences[1]})\n",
    "# pd.DataFrame(np.array(model_sequences.loc[:, 2:].astype(int))).to_csv(\"clean_10k_real.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# file_path = \"/Users/shakedahronoviz/Genome-AC-GAN/experiment_results/old_model_80%/5001_output.hapt\"\n",
    "# model_sequences = pd.read_csv(file_path, sep=' ', header=None)\n",
    "# model_sequences = model_sequences.drop(columns=list(model_sequences.columns)[-1], axis=1)\n",
    "# model_sequences.columns = [column + 2 for column in list(model_sequences.columns)]\n",
    "# model_sequences.insert(loc=0, column=0, value=\"none\")\n",
    "# model_sequences.insert(loc=1, column=1, value='none')\n",
    "# model_sequences[0] = \"model_name\"\n",
    "# x = pd.DataFrame({'label': model_sequences[0], 'ind': model_sequences[1]})\n",
    "# pd.DataFrame(np.array(model_sequences.loc[:, 2:].astype(int))).to_csv(\"clean_old_model_80%.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
