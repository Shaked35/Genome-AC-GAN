{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Metal device set to: Apple M1 Pro\n",
      " Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:19:46.306489: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-26 15:19:46.306514: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.stats import sem\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "\n",
    "\n",
    "from utils.util import *\n",
    "\n",
    "try:\n",
    "    import ot\n",
    "\n",
    "    ot_loaded = True\n",
    "except ModuleNotFoundError:\n",
    "    ot_loaded = False\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    sm_loaded = True\n",
    "except ModuleNotFoundError:\n",
    "    sm_loaded = False\n",
    "init_gpus()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "models_to_data = {\n",
    "    \"Real\": {\n",
    "        \"path\": \"resource/test_0.2_super_pop.csv\",\n",
    "        \"color\": \"black\",\n",
    "        \"type\": \"dataset\"\n",
    "    },\n",
    "    \"Train Real\": {\n",
    "        \"path\": \"resource/train_0.8_super_pop.csv\",\n",
    "        \"color\": \"gray\",\n",
    "        \"type\": \"dataset\"\n",
    "    },\n",
    "    \"RBM New\": {\n",
    "        \"path\": \"fake_genotypes_sequences/preview_sequences/10K_SNP_GAN_AG_10800Epochs.hapt\",\n",
    "        \"color\": \"yellow\"\n",
    "    },\n",
    "    \"WGAN\": {\n",
    "        \"path\": \"fake_genotypes_sequences/preview_sequences/10K_WGAN.hapt\",\n",
    "        \"color\": \"purple\"\n",
    "    },\n",
    "    \"GAN Old Model Retrain\": {\n",
    "        \"path\": \"experiment_results/old_model_80%_10K/10000_output.hapt\",\n",
    "        \"color\": \"brown\",\n",
    "        \"type\": \"retrain_old_model\"\n",
    "    },\n",
    "    \"Genome-AC-GAN By National Population\": {\n",
    "        \"path\": \"fake_genotypes_sequences/new_sequences/polyloss_ce_10k_sub_pop/8000_genotypes.hapt\",\n",
    "        \"color\": \"green\",\n",
    "        \"type\": \"new_model\"\n",
    "    },\n",
    "    \"Genome-AC-GAN By Continental Population\": {\n",
    "        \"path\": \"fake_genotypes_sequences/new_sequences/polyloss_ce_10k_pop/9000_genotypes.hapt\",\n",
    "        \"color\": \"blue\",\n",
    "        \"type\": \"new_model\"\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "output_dir = os.environ.get(\"output_dir\", DEFAULT_EXPERIMENT_OUTPUT_DIR)\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "compute_AATS = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "color_palette = {model_name: values[\"color\"] for (model_name, values) in models_to_data.items()}\n",
    "sns.set_palette(color_palette.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_analysis_data_agg_tests(models_to_data: dict, number_of_datasets: int):\n",
    "    transformations = {'to_minor_encoding': False, 'min_af': 0, 'max_af': 1}\n",
    "\n",
    "    model_keep_all_snps, sample_info = dict(), dict()\n",
    "    # initialize real data\n",
    "    real_data = models_to_data['Real']\n",
    "    real_model_sequences, number_of_samples = create_single_dataset(\n",
    "        real_data, f\"../{real_data['path']}\", 'Real', 0,\n",
    "        sample_info)\n",
    "    datasets = {'Real': [np.array(real_model_sequences.loc[:, 2:].astype(int))]}\n",
    "    full_datasets = {'Real': np.array(real_model_sequences.loc[:, 2:].astype(int))}\n",
    "    print('Real: ', datasets['Real'][0].shape)\n",
    "    # init all other datasets\n",
    "    for model_name, data in models_to_data.items():\n",
    "        if model_name != 'Real':\n",
    "            model_datasets = []\n",
    "            file_path = f\"../{data['path']}\"\n",
    "            for dataset_number in range(1, number_of_datasets + 1):\n",
    "\n",
    "                model_sequences, _ = create_single_dataset(data, file_path, model_name,\n",
    "                                                           number_of_samples,\n",
    "                                                           sample_info)\n",
    "                model_datasets.append(np.array(model_sequences.loc[:, 2:].astype(int)))\n",
    "\n",
    "                if dataset_number % 5 == 0:\n",
    "                    print(f\"Finished init model {model_name} number {dataset_number}\")\n",
    "            datasets[model_name] = model_datasets\n",
    "\n",
    "            model_sequences, _ = create_single_dataset(data, file_path, model_name,\n",
    "                                                       number_of_samples,\n",
    "                                                       sample_info, filter_number_of_sequences=False)\n",
    "            full_datasets[model_name] = np.array(model_sequences.loc[:, 2:].astype(int))\n",
    "\n",
    "    extra_sample_info = pd.DataFrame(np.concatenate(list(sample_info.values())), columns=['label', 'id'])\n",
    "    print(\"Dictionary of datasets:\", len(datasets))\n",
    "    return extra_sample_info, sample_info, datasets, transformations, model_keep_all_snps, number_of_samples, full_datasets\n",
    "\n",
    "\n",
    "def create_single_dataset(data, file_path, model_name, number_of_samples, sample_info, filter_number_of_sequences=True):\n",
    "    if data.get(\"type\", \"\") == \"dataset\":\n",
    "        model_sequences_df = pd.read_csv(file_path)\n",
    "        columns = get_relevant_columns(model_sequences_df, model_sequences_df.columns[:2])\n",
    "        model_sequences = model_sequences_df[columns]\n",
    "        columns = [int(i) for i in columns]\n",
    "        model_sequences.columns = columns\n",
    "        model_sequences = model_sequences.sample(frac=1).reset_index(drop=True)\n",
    "    else:\n",
    "        model_sequences = pd.read_csv(file_path, sep=' ', header=None)\n",
    "        if data.get(\"type\", \"\") == \"new_model\":\n",
    "            model_sequences.columns = [column if column == 0 else column + 1 for column in model_sequences.columns]\n",
    "            # Calculate the category counts\n",
    "            if filter_number_of_sequences:\n",
    "                category_counts = model_sequences[0].value_counts()\n",
    "                sample_counts = (category_counts / category_counts.sum() * (number_of_samples)).astype(int)\n",
    "                model_sequences = model_sequences.sample(frac=1).reset_index(drop=True)\n",
    "                # Sample rows from each category\n",
    "                model_sequences = model_sequences.groupby(0).apply(\n",
    "                    lambda x: x.sample(sample_counts[x.name])).reset_index(drop=True)\n",
    "\n",
    "            model_sequences.insert(0, 1, [f\"AG{sample_id}\" for sample_id in range(model_sequences.shape[0])])\n",
    "        if data.get(\"type\", \"\") == \"retrain_old_model\":\n",
    "            model_sequences = model_sequences.drop(columns=list(model_sequences.columns)[-1], axis=1)\n",
    "            model_sequences.columns = [column + 2 for column in list(model_sequences.columns)]\n",
    "            model_sequences.insert(loc=0, column=0, value=\"none\")\n",
    "            model_sequences.insert(loc=1, column=1, value='none')\n",
    "    if model_name == 'Real':\n",
    "        number_of_samples = len(model_sequences)\n",
    "\n",
    "    if filter_number_of_sequences:\n",
    "        if model_sequences.shape[0] > number_of_samples:\n",
    "            model_sequences = model_sequences.drop(\n",
    "                index=np.sort(\n",
    "                    np.random.choice(np.arange(model_sequences.shape[0]),\n",
    "                                     size=model_sequences.shape[0] - number_of_samples,\n",
    "                                     replace=False)))\n",
    "    # overwrite file first column to set the label name chosen in infiles (eg GAN, etc):\n",
    "    model_sequences[0] = model_name\n",
    "    sample_info[model_name] = pd.DataFrame({'label': model_sequences[0], 'ind': model_sequences[1]})\n",
    "    return model_sequences, number_of_samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real:  (1002, 10000)\n",
      "Dictionary of datasets: 7\n"
     ]
    }
   ],
   "source": [
    "extra_sample_info, sample_info, datasets, transformations, model_keep_all_snps, number_of_samples, full_datasets = load_analysis_data_agg_tests(models_to_data, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def plot_pca_comparison(models):\n",
    "    model_to_wasserstein_dists = {}\n",
    "    all_best_sequences = {}\n",
    "    # Extract the 'Real' model data\n",
    "    real_model = models['Real'][0]\n",
    "    all_best_sequences['Real'] = real_model\n",
    "    # Perform PCA on the 'Real' model\n",
    "    pca_real = PCA(n_components=2)\n",
    "    pca_real.fit(real_model)\n",
    "    pca_real_transformed = pca_real.transform(real_model)\n",
    "\n",
    "    # Plotting parameters\n",
    "    num_models = len(models) - 1\n",
    "    num_rows = int(np.ceil(num_models / 3))\n",
    "    num_cols = min(num_models, 3)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
    "\n",
    "    for i, (model_name, model_sequences) in enumerate(models.items()):\n",
    "        # Skip 'Real' model\n",
    "        if model_name == 'Real':\n",
    "            continue\n",
    "\n",
    "        print(f\"start model: {model_name} get best sequences\")\n",
    "        all_wasserstein_dist, best_model_sequence, best_pca_transformed = \\\n",
    "            get_best_pca_wasserstein(model_sequences, pca_real_transformed)\n",
    "        mean_all_wasserstein_dist = np.mean(all_wasserstein_dist)\n",
    "        std_all_wasserstein_dist = np.std(all_wasserstein_dist)\n",
    "        min_all_wasserstein_dist = np.min(all_wasserstein_dist)\n",
    "        model_to_wasserstein_dists[model_name] = all_wasserstein_dist\n",
    "        all_best_sequences[model_name] = best_model_sequence\n",
    "        print(\n",
    "            f\"finished model: {model_name} get best sequences with mean: {mean_all_wasserstein_dist}, std: {std_all_wasserstein_dist}, min: {min_all_wasserstein_dist}\")\n",
    "        # Set subplot position\n",
    "        position = i - 1\n",
    "        row = position // num_cols\n",
    "        col = position % num_cols\n",
    "\n",
    "        # Plot PCA comparison\n",
    "        ax = axes[row, col]\n",
    "        ax.scatter(pca_real_transformed[:, 0], pca_real_transformed[:, 1], color=color_palette['Real'], label='Real',\n",
    "                   alpha=0.8)\n",
    "        ax.scatter(best_pca_transformed[:, 0], best_pca_transformed[:, 1], color=color_palette[model_name],\n",
    "                   label=model_name, alpha=0.5)\n",
    "        ax.set_title(\n",
    "            f'{model_name}\\nWasserstein Distance Mean: {mean_all_wasserstein_dist:.4f}\\nWasserstein Distance Minimum: {min_all_wasserstein_dist:.4f}\\nWasserstein Distance Std: {std_all_wasserstein_dist:.4f}',\n",
    "            fontsize=18)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"pca2_on_test_real.jpg\"))\n",
    "    plt.show()\n",
    "    return model_to_wasserstein_dists, all_best_sequences\n",
    "\n",
    "\n",
    "def get_best_pca_wasserstein(model_sequences, pca_real_transformed):\n",
    "    all_wasserstein_dist = []\n",
    "    best_wasserstein_dist = np.inf\n",
    "    best_model_sequence = None\n",
    "    best_pca_transformed = None\n",
    "    for model_sequence in model_sequences:\n",
    "        # Perform PCA on the current model\n",
    "        pca_model = PCA(n_components=2)\n",
    "        pca_model.fit(model_sequence)\n",
    "        pca_model_transformed = pca_model.transform(model_sequence)\n",
    "\n",
    "        # Calculate Wasserstein distance\n",
    "        tmp_wasserstein_dist = wasserstein_distance(pca_real_transformed.flatten(),\n",
    "                                                    pca_model_transformed.flatten())\n",
    "        all_wasserstein_dist.append(tmp_wasserstein_dist)\n",
    "        if tmp_wasserstein_dist < best_wasserstein_dist:\n",
    "            best_wasserstein_dist = tmp_wasserstein_dist\n",
    "            best_model_sequence = model_sequence\n",
    "            best_pca_transformed = pca_model_transformed\n",
    "    return all_wasserstein_dist, best_model_sequence, best_pca_transformed\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start model: Train Real get best sequences\n",
      "finished model: Train Real get best sequences with mean: 0.2510893179993068, std: 0.02841471409746392, min: 0.22267460390184288\n",
      "start model: RBM New get best sequences\n",
      "finished model: RBM New get best sequences with mean: 0.31770472394067684, std: 0.05450903719892028, min: 0.26319568674175653\n",
      "start model: WGAN get best sequences\n",
      "finished model: WGAN get best sequences with mean: 0.3494434289766629, std: 0.04768833731047639, min: 0.3017550916661865\n",
      "start model: GAN Old Model Retrain get best sequences\n",
      "finished model: GAN Old Model Retrain get best sequences with mean: 0.7977748352525551, std: 0.023929067017368133, min: 0.773845768235187\n",
      "start model: Genome-AC-GAN By National Population get best sequences\n",
      "finished model: Genome-AC-GAN By National Population get best sequences with mean: 0.24660459348626415, std: 0.03239173853102542, min: 0.21421285495523873\n",
      "start model: Genome-AC-GAN By Continental Population get best sequences\n",
      "finished model: Genome-AC-GAN By Continental Population get best sequences with mean: 0.2915179214311956, std: 0.021141299840875205, min: 0.2703766215903204\n"
     ]
    }
   ],
   "source": [
    "model_to_wasserstein_dists, all_best_sequences = plot_pca_comparison(datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_names = list(model_to_wasserstein_dists.keys())\n",
    "model_names = [\"\\n\".join(model_name.split(\"By\")) for model_name in model_names]\n",
    "model_names = [\"\\n\".join(model_name.split(\"Model\")) for model_name in model_names]\n",
    "wasserstein_distances = list(model_to_wasserstein_dists.values())\n",
    "\n",
    "p_values = []\n",
    "for i in range(len(model_names)):\n",
    "    for j in range(i + 1, len(model_names)):\n",
    "        p_values.append(1 - stats.ttest_ind(wasserstein_distances[i], wasserstein_distances[j]).pvalue)\n",
    "\n",
    "# Reshape the p_values into a 2D matrix\n",
    "n = len(model_names)\n",
    "p_values_matrix = np.zeros((n, n))\n",
    "p_values_matrix[np.triu_indices(n, 1)] = p_values\n",
    "p_values_matrix += p_values_matrix.T\n",
    "\n",
    "# Create a plot matrix of the p-values\n",
    "fig, ax = plt.subplots(figsize=(15, 15))  # Increase the size of the plot\n",
    "im = ax.imshow(p_values_matrix, cmap='coolwarm', vmin=0, vmax=1)\n",
    "ax.set_xticks(np.arange(len(model_names)))\n",
    "ax.set_yticks(np.arange(len(model_names)))\n",
    "ax.set_xticklabels(model_names, rotation=45)\n",
    "ax.set_yticklabels(model_names)\n",
    "\n",
    "# Add numerical values in the matrix\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        text = ax.text(j, i, f'{p_values_matrix[i, j] * 100:.5f}%', ha='center', va='center', color='w', fontsize=15)\n",
    "\n",
    "plt.colorbar(im)\n",
    "ax.grid(False)  # Remove the grid\n",
    "plt.savefig(os.path.join(output_dir, \"P-values wasserstein_distances\"))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum_alleles_by_position, allele_frequency, is_fixed = build_allele_frequency(full_datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_reg(x, y, keys, statname, col, ax=None):\n",
    "    \"\"\"\n",
    "    Plot for x versus y with regression scores and returns correlation coefficient\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array, scalar\n",
    "    y : array, scalar\n",
    "    statname : str\n",
    "        'Allele frequency' LD' or '3 point correlation' etc.\n",
    "    col : str, color code\n",
    "        color\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    lims = [np.min(x), np.max(x)]\n",
    "    r, _ = pearsonr(x, y)\n",
    "    if sm_loaded:\n",
    "        reg = sm.OLS(x, y).fit()\n",
    "    if ax is None:\n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "    if len(x) < 100:\n",
    "        alpha = 1\n",
    "    else:\n",
    "        alpha = .6\n",
    "    ax.plot(x, y, label=f\"cor={round(round(r, 3) * 100, 3)}%\", c=col, marker='o', lw=0, alpha=alpha)\n",
    "    ax.plot(lims, lims, ls='--', alpha=1, c='black')\n",
    "    ax.set_xlabel(f'{statname} in {keys[0]}', fontsize=15)\n",
    "    ax.set_ylabel(f'{statname} in synthetic data', fontsize=15)\n",
    "    ax.legend(fontsize=20)\n",
    "    return r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_allele_frequency(allele_frequency, file_name, maf, highest=False):\n",
    "    # Plotting Allele frequencies in Generated vs Real\n",
    "    # below a certain real frequency\n",
    "    figwi = 14\n",
    "    l, c = np.ceil(len(allele_frequency) / 4), 3\n",
    "    plt.figure(figsize=(figwi, figwi * l / c))\n",
    "    if highest:\n",
    "        maf = 1 - maf\n",
    "        keep = (allele_frequency['Real'] >= maf)\n",
    "    else:\n",
    "        keep = (allele_frequency['Real'] <= maf)\n",
    "    for i, (model_name, val) in enumerate(allele_frequency.items()):\n",
    "        model_name_display = \"\\n\".join(model_name.split(\"By\"))\n",
    "        model_name_display = \"\\n\".join(model_name_display.split(\"Model\"))\n",
    "        if model_name != 'Real':\n",
    "            ax = plt.subplot(int(l), c, i)\n",
    "            plot_reg(x=allele_frequency['Real'][keep], y=val[keep],\n",
    "                     keys=['Real', model_name_display], statname=\"Allele frequency\",\n",
    "                     col=color_palette[model_name], ax=ax)\n",
    "            plt.title(f'{model_name_display} vs Real', fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, file_name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_allele_frequency(allele_frequency, 'total_allele_frequency.jpg', 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_allele_frequency(allele_frequency, 'zoom_lowest_total_allele_frequency.jpg', 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_allele_frequency(allele_frequency, 'zoom_highest_total_allele_frequency.jpg', 0.2, highest=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_analysis_data_for_preview_tests(model_name_to_input_file: dict):\n",
    "    transformations = {'to_minor_encoding': False, 'min_af': 0, 'max_af': 1}\n",
    "\n",
    "    datasets, model_keep_all_snps, sample_info = dict(), dict(), dict()\n",
    "    number_of_samples = 0\n",
    "    for model_name, data in model_name_to_input_file.items():\n",
    "        file_path = f\"../{data['path']}\"\n",
    "        print(model_name, \"loaded from\", file_path)\n",
    "        if file_path.endswith('.csv'):\n",
    "            model_sequences = pd.read_csv(file_path)\n",
    "            columns = get_relevant_columns(model_sequences, model_sequences.columns[:2])\n",
    "            model_sequences = model_sequences[columns]\n",
    "            columns = [int(i) for i in columns]\n",
    "            model_sequences.columns = columns\n",
    "            number_of_samples = len(model_sequences)\n",
    "\n",
    "        else:\n",
    "            model_sequences = pd.read_csv(file_path, sep=' ', header=None)\n",
    "            if 'Genome-AC-GAN' in model_name:\n",
    "                model_sequences.columns = [column if column == 0 else column + 1 for column in model_sequences.columns]\n",
    "                model_sequences.insert(0, 1, [f\"AG{sample_id}\" for sample_id in range(model_sequences.shape[0])])\n",
    "            if model_sequences.shape[1] == 808:  # special case for a specific file that had an extra empty column\n",
    "                model_sequences = model_sequences.drop(columns=model_sequences.columns[-1])\n",
    "            if model_sequences.shape[0] > number_of_samples:\n",
    "                model_sequences = model_sequences.drop(\n",
    "                    index=np.sort(\n",
    "                        np.random.choice(np.arange(model_sequences.shape[0]),\n",
    "                                         size=model_sequences.shape[0] - number_of_samples,\n",
    "                                         replace=False))\n",
    "                )\n",
    "            if 'Old Model' in model_name :\n",
    "                model_sequences = model_sequences.drop(columns=list(model_sequences.columns)[-1], axis=1)\n",
    "                model_sequences.columns = [column + 2 for column in list(model_sequences.columns)]\n",
    "                model_sequences.insert(loc=0, column=0, value=\"none\")\n",
    "                model_sequences.insert(loc=1, column=1, value='none')\n",
    "        # overwrite file first column to set the label name chosen in infiles (eg GAN, etc):\n",
    "        model_sequences[0] = model_name\n",
    "        sample_info[model_name] = pd.DataFrame({'label': model_sequences[0], 'ind': model_sequences[1]})\n",
    "        datasets[model_name] = np.array(model_sequences.loc[:, 2:].astype(int))\n",
    "\n",
    "        # transformations can be maf filtering, recoding into major=0/minor=1 format\n",
    "        if transformations is not None:\n",
    "            datasets[model_name], model_keep_all_snps[model_name] = datatransform(datasets[model_name],\n",
    "                                                                                  **transformations)\n",
    "        print(model_name, datasets[model_name].shape)\n",
    "    extra_sample_info = pd.DataFrame(np.concatenate(list(sample_info.values())), columns=['label', 'id'])\n",
    "    print(\"Dictionary of datasets:\", len(datasets))\n",
    "    return extra_sample_info, sample_info, datasets, transformations, model_keep_all_snps, number_of_samples\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extra_sample_info, sample_info, datasets, transformations, model_keep_all_snps, number_of_samples = load_analysis_data_for_preview_tests(\n",
    "    models_to_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum_alleles_by_position, allele_frequency, is_fixed = build_allele_frequency(datasets)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Plotting Allele frequencies in Generated vs Real\n",
    "# # higher than a certain real frequency\n",
    "# figwi = 12\n",
    "# l, c = np.ceil(len(allele_frequency) / 4), 3\n",
    "# plt.figure(figsize=(figwi, figwi * l / c))\n",
    "# maf = 0.3\n",
    "# keep = (allele_frequency['Real'] >= 1 - maf)\n",
    "# for i, (model_name, val) in enumerate(allele_frequency.items()):\n",
    "#     model_name_display = \"\\n\".join(model_name.split(\"By\"))\n",
    "#     model_name_display = \"\\n\".join(model_name_display.split(\"Model\"))\n",
    "#     if model_name != 'Real':\n",
    "#         ax = plt.subplot(int(l), c, i)\n",
    "#         plot_reg(x=allele_frequency['Real'][keep], y=val[keep],\n",
    "#                  keys=['Real', model_name_display], statname=\"Allele frequency\",\n",
    "#                  col=color_palette[model_name], ax=ax)\n",
    "#         plt.title(f'{model_name_display} vs Real')\n",
    "# plt.suptitle(f'Zoom in Allele Frequency highest {maf}% \\n')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(output_dir, 'zoom_highest_total_allele_frequency.jpg'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def switch_random_positions(array, n):\n",
    "#     # Flatten the array to 1D\n",
    "#     flattened_array = array.flatten()\n",
    "#\n",
    "#     # Get the indices where the value is 0 or 1\n",
    "#     zero_indices = np.where(flattened_array == 0)[0]\n",
    "#     one_indices = np.where(flattened_array == 1)[0]\n",
    "#\n",
    "#     # Randomly select n indices to switch from 0 to 1\n",
    "#     zero_to_one_indices = np.random.choice(zero_indices, size=n, replace=False)\n",
    "#\n",
    "#     # Randomly select n indices to switch from 1 to 0\n",
    "#     one_to_zero_indices = np.random.choice(one_indices, size=n, replace=False)\n",
    "#\n",
    "#     # Switch the values at the selected indices\n",
    "#     flattened_array[zero_to_one_indices] = 1\n",
    "#     flattened_array[one_to_zero_indices] = 0\n",
    "#\n",
    "#     # Reshape the flattened array back to its original shape\n",
    "#     modified_array = flattened_array.reshape(array.shape)\n",
    "#\n",
    "#     return modified_array\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# random_positions = datasets['Real'].shape[0] * 100\n",
    "# print(random_positions)\n",
    "# datasets['Copy'] = switch_random_positions(datasets['Real'], random_positions)\n",
    "# real_aug = pd.DataFrame(switch_random_positions(datasets['Real'], random_positions))\n",
    "# real_aug = real_aug.sample(frac=1, random_state=42)  # Set random_state for reproducibility\n",
    "# real_aug.reset_index(drop=True, inplace=True)  # Reset the index of the shuffled DataFrame\n",
    "# real_aug.to_csv(\"augmented_real_data.csv\", index=False)\n",
    "# real_aug"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(15, 5 * len(model_name_to_input_file.keys())))\n",
    "# l, c = len(model_name_to_input_file.keys()) - 1, 2\n",
    "# plt.figure(figsize=(figwi * c / 4, figwi * l / 4))\n",
    "# win = 1\n",
    "# for i, model_name in enumerate(model_name_to_input_file.keys()):\n",
    "#     if model_name == 'Real': continue\n",
    "#     plt.subplot(l, c, win)\n",
    "#     win += 1\n",
    "#     plt.plot(allele_frequency['Real'][(sum_alleles_by_position[model_name] == 0)], alpha=1, marker='.', lw=0)\n",
    "#     plt.ylabel(\"Allele frequency in Real\")\n",
    "#     plt.title(\"Real frequency of alleles \\n absent from {}\".format(model_name))\n",
    "#     plt.subplot(l, c, win)\n",
    "#     win += 1\n",
    "#     plt.hist(allele_frequency['Real'][(sum_alleles_by_position[model_name] == 0)], alpha=1)\n",
    "#     plt.title(\"Hist real freq of alleles \\n absent from {}\".format(model_name))\n",
    "#\n",
    "# plt.suptitle(\"Plotting allele frequency characteristics \\n\\n\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(output_dir, \"RealAC_for_0fixed_sites.pdf\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# random_df = pd.DataFrame(np.random.randint(low=0, high=2, size=(datasets['Real'].shape[0], datasets['Real'].shape[1])))\n",
    "# random_df.to_csv(\"random_data.csv\", index=False)\n",
    "# random_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def find_different_positions(array1, array2):\n",
    "#     # Find positions where array1 and array2 have different values\n",
    "#     different_positions = np.where(array1 != array2)\n",
    "#\n",
    "#     return different_positions\n",
    "#\n",
    "#\n",
    "# different_positions = find_different_positions(real_aug.to_numpy(), datasets['Real'])\n",
    "# print(len(different_positions[1]) / (datasets['Real'].shape[0] * datasets['Real'].shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from scipy.stats import entropy\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy import stats\n",
    "# from sklearn.metrics import mutual_info_score\n",
    "#\n",
    "#\n",
    "# def statistical_analysis_test(real_df, synthetic_df):\n",
    "#     # Perform statistical analysis on the datasets\n",
    "#     # Calculate summary statistics and compare distributions\n",
    "#\n",
    "#     # Calculate mean and variance for real and synthetic datasets\n",
    "#     real_mean = real_df.mean()\n",
    "#     synthetic_mean = synthetic_df.mean()\n",
    "#\n",
    "#     # Perform t-test between real and synthetic means\n",
    "#     t_stat, p_value = stats.ttest_ind(real_mean, synthetic_mean)\n",
    "#\n",
    "#     # Perform Kolmogorov-Smirnov test between real and synthetic distributions\n",
    "#     ks_stat, ks_p_value = stats.ks_2samp(real_df.values.flatten(), synthetic_df.values.flatten())\n",
    "#\n",
    "#     # Return the results\n",
    "#     return t_stat, p_value, ks_stat, ks_p_value\n",
    "#\n",
    "#\n",
    "# def information_theory_test(real_df, synthetic_df):\n",
    "#     # Perform information theory test on the datasets\n",
    "#     # Calculate entropy, mutual information, or Kullback-Leibler divergence\n",
    "#\n",
    "#     # Calculate entropy for real and synthetic datasets\n",
    "#     real_entropy = calculate_entropy(real_df)\n",
    "#     synthetic_entropy = calculate_entropy(synthetic_df)\n",
    "#\n",
    "#     # Calculate mutual information between real and synthetic datasets\n",
    "#     mutual_info = mutual_info_score(real_df.values.flatten(), synthetic_df.values.flatten())\n",
    "#\n",
    "#     # Calculate Kullback-Leibler divergence between real and synthetic distributions\n",
    "#     kl_divergence = calculate_kl_divergence(real_df, synthetic_df)\n",
    "#\n",
    "#     # Return the results\n",
    "#     return real_entropy, synthetic_entropy, mutual_info, kl_divergence\n",
    "#\n",
    "#\n",
    "# # Helper functions\n",
    "#\n",
    "# def calculate_entropy(data):\n",
    "#     # Calculate entropy for a given dataset\n",
    "#     n_samples, n_features = data.shape\n",
    "#     entropy = np.zeros(n_features)\n",
    "#\n",
    "#     for i in range(n_features):\n",
    "#         feature_counts = data.iloc[:, i].value_counts()\n",
    "#         probabilities = feature_counts / n_samples\n",
    "#         entropy[i] = stats.entropy(probabilities)\n",
    "#\n",
    "#     return entropy\n",
    "#\n",
    "#\n",
    "# def calculate_kl_divergence(p, q, epsilon=1e-9):\n",
    "#     # Calculate Kullback-Leibler divergence between two datasets\n",
    "#     kl_divergence = np.zeros(p.shape[1])\n",
    "#\n",
    "#     for i in range(p.shape[1]):\n",
    "#         p_smoothed = p.iloc[:, i] + epsilon\n",
    "#         q_smoothed = q.iloc[:, i] + epsilon\n",
    "#         kl_divergence[i] = entropy(p_smoothed, q_smoothed)\n",
    "#\n",
    "#     return kl_divergence\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# real_entropy_by_pop, synthetic_entropy_by_pop, mutual_info_by_pop, kl_divergence_by_pop = information_theory_test(\n",
    "#     pd.DataFrame(datasets['Real']),\n",
    "#     pd.DataFrame(datasets[\n",
    "#                      'Genome-AC-GAN super pop']))\n",
    "# t_stat_by_pop, p_value_by_pop, ks_stat_by_pop, ks_p_value_by_pop = statistical_analysis_test(\n",
    "#     pd.DataFrame(datasets['Real']),\n",
    "#     pd.DataFrame(datasets['Genome-AC-GAN super pop']))\n",
    "#\n",
    "# real_entropy_by_sub_pop, synthetic_entropy_by_sub_pop, mutual_info_by_sub_pop, kl_divergence_by_sub_pop = information_theory_test(\n",
    "#     pd.DataFrame(datasets['Real']),\n",
    "#     pd.DataFrame(datasets[\n",
    "#                      'Genome-AC-GAN super pop']))\n",
    "# t_stat_by_sub_pop, p_value_by_sub_pop, ks_stat_by_sub_pop, ks_p_value_by_sub_pop = statistical_analysis_test(\n",
    "#     pd.DataFrame(datasets['Real']),\n",
    "#     pd.DataFrame(datasets['Genome-AC-GAN sub pop']))\n",
    "#\n",
    "# real_entropy_wgan, synthetic_entropy_wgan, mutual_info_wgan, kl_divergence_wgan = information_theory_test(\n",
    "#     pd.DataFrame(datasets['Real']), pd.DataFrame(datasets['WGAN']))\n",
    "# t_stat_wgan, p_value_wgan, ks_stat_wgan, ks_p_value_wgan = statistical_analysis_test(pd.DataFrame(datasets['Real']),\n",
    "#                                                                                      pd.DataFrame(datasets['WGAN']))\n",
    "#\n",
    "# real_entropy_rbm, synthetic_entropy_rbm, mutual_info_rbm, kl_divergence_rbm = information_theory_test(\n",
    "#     pd.DataFrame(datasets['Real']), pd.DataFrame(datasets['RBM_new']))\n",
    "# t_stat_rbm, p_value_rbm, ks_stat_rbm, ks_p_value_rbm = statistical_analysis_test(pd.DataFrame(datasets['Real']),\n",
    "#                                                                                  pd.DataFrame(datasets['RBM_new']))\n",
    "#\n",
    "# real_entropy_real, synthetic_entropy_real, mutual_info_real, kl_divergence_real = information_theory_test(\n",
    "#     pd.DataFrame(datasets['Real']), pd.DataFrame(datasets['Real']))\n",
    "# t_stat_real, p_value_real, ks_stat_real, ks_p_value_real = statistical_analysis_test(pd.DataFrame(datasets['Real']),\n",
    "#                                                                                      pd.DataFrame(datasets['Real']))\n",
    "#\n",
    "# real_entropy_random, synthetic_entropy_random, mutual_info_random, kl_divergence_random = information_theory_test(\n",
    "#     pd.DataFrame(datasets['Real']), random_df)\n",
    "# t_stat_random, p_value_random, ks_stat_random, ks_p_value_random = statistical_analysis_test(\n",
    "#     pd.DataFrame(datasets['Real']), random_df)\n",
    "#\n",
    "# _, _, mutual_info_aug, kl_divergence_aug = information_theory_test(pd.DataFrame(datasets['Real']), real_aug)\n",
    "# t_stat_aug, p_value_aug, ks_stat_aug, ks_p_value_aug = statistical_analysis_test(pd.DataFrame(datasets['Real']),\n",
    "#                                                                                  real_aug)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# privacy_results = pd.DataFrame(\n",
    "#     {\"test_type\": [\"real vs real\", \"real vs real_switched\", \"real vs random\", \"real vs wgan\", \"real vs rbm\",\n",
    "#                    \"real vs new super pop\", \"real vs new sub pop\"],\n",
    "#      \"mutual_info\": [round(mutual_info_real, 6), round(mutual_info_aug, 6), round(mutual_info_random, 6),\n",
    "#                      round(mutual_info_wgan, 6), round(mutual_info_rbm, 6), round(mutual_info_by_pop, 6),\n",
    "#                      round(mutual_info_by_sub_pop, 7)],\n",
    "#      \"t_stat\": [round(t_stat_real, 7), round(t_stat_aug, 7), round(t_stat_random, 7), round(t_stat_wgan, 7),\n",
    "#                 round(t_stat_rbm, 7), round(t_stat_by_pop, 7), round(t_stat_by_sub_pop, 7)],\n",
    "#      \"p_value\": [round(p_value_real, 7), round(p_value_aug, 7), round(p_value_random, 7), round(p_value_wgan, 7),\n",
    "#                  round(p_value_rbm, 7), round(p_value_by_pop, 7), round(p_value_by_sub_pop, 7)],\n",
    "#      \"ks_stat\": [round(ks_stat_real, 7), round(ks_stat_aug, 7), round(ks_stat_random, 7), round(ks_stat_wgan, 7),\n",
    "#                  round(ks_stat_rbm, 7), round(ks_stat_by_pop, 7), round(ks_stat_by_sub_pop, 7)]})\n",
    "# privacy_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def re_identification_risk(df_real, df_synthetic):\n",
    "#     # Calculate the re-identification risk based on distance metrics\n",
    "#     euclidean_dist = distance.euclidean(df_real.values.flatten(), df_synthetic.values.flatten())\n",
    "#     cosine_dist = distance.cosine(df_real.values.flatten(), df_synthetic.values.flatten())\n",
    "#     re_identification_risk = euclidean_dist + cosine_dist\n",
    "#     return re_identification_risk\n",
    "#\n",
    "#\n",
    "# print(\n",
    "#     re_identification_risk(pd.DataFrame(datasets['Real']), pd.DataFrame(datasets['Genome-AC-GAN sub pop'])),\n",
    "#     re_identification_risk(pd.DataFrame(datasets['Real']), pd.DataFrame(datasets['RBM_new'])),\n",
    "#     re_identification_risk(pd.DataFrame(datasets['Real']), random_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "#\n",
    "#\n",
    "# def generalization_accuracy(real_df, synthetic_df, target_column):\n",
    "#     X = pd.concat([real_df, synthetic_df])\n",
    "#     y = pd.concat([pd.Series([1] * len(real_df)), pd.Series([0] * len(synthetic_df))])\n",
    "#\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#     model = LogisticRegression()\n",
    "#     model.fit(X_train, y_train)\n",
    "#\n",
    "#     return model.score(X_test, y_test)\n",
    "#\n",
    "#\n",
    "# generalization_accuracy(pd.DataFrame(datasets['Real']),\n",
    "#                         pd.DataFrame(datasets['Genome-AC-GAN super pop']), target_column)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def calculate_hamming_distance(array1, array2):\n",
    "#     return np.sum(array1 != array2, axis=1)\n",
    "#\n",
    "#\n",
    "# def add_laplace_noise(values, epsilon):\n",
    "#     sensitivity = 1.0  # Sensitivity of the Hamming distance is 1\n",
    "#     scale = sensitivity / epsilon\n",
    "#     noise = np.random.laplace(loc=0.0, scale=scale, size=len(values))\n",
    "#     return values + noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(datasets['Real']).shape, pd.DataFrame(datasets['Genome-AC-GAN super pop']).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hamming_distances = calculate_hamming_distance(datasets['Real'], datasets['Genome-AC-GAN super pop'])\n",
    "# epsilon = 2\n",
    "# noisy_hamming_distances = add_laplace_noise(hamming_distances, epsilon)\n",
    "# print(noisy_hamming_distances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Plotting Allele frequencies in Generated vs Real\n",
    "# l, c = np.ceil(len(allele_frequency) / 3), 3\n",
    "# plt.figure(figsize=(figwi, figwi * l / c))\n",
    "# for i, (model_name, val) in enumerate(allele_frequency.items()):\n",
    "#     ax = plt.subplot(int(l), 3, i + 1)\n",
    "#     plotreg(x=allele_frequency['Real'], y=val,\n",
    "#             keys=['Real', model_name], statname=\"Allele frequency\",\n",
    "#             col=color_palette[model_name], ax=ax)\n",
    "#     plt.title(f'Allele Frequencies {model_name} vs Real')\n",
    "# plt.suptitle(f'Allele Frequencies vs Real \\n\\n')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(output_dir, 'AC_generated_vs_Real.pdf'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# score_list = []\n",
    "# number_of_components = 6  # change to compute more PCs\n",
    "#\n",
    "# method_name = \"model_results_on_real_pca\"\n",
    "# print(f'Computing {method_name} ...')\n",
    "# pca = PCA(n_components=number_of_components)\n",
    "# # real_pca = pca.fit_transform(datasets['Real'])\n",
    "# pca.fit_transform(  #datasets['Real']\n",
    "#     np.concatenate(list(datasets.values()))\n",
    "# )\n",
    "#\n",
    "# pcs = pca.transform(np.concatenate(list(datasets.values())))\n",
    "#\n",
    "# pcdf = pd.DataFrame(pcs, columns=[\"PC{}\".format(x + 1) for x in np.arange(pcs.shape[1])])\n",
    "# pcdf[\"label\"] = extra_sample_info.label.astype('category')\n",
    "# plotPCAallfigs(pcdf, method_name, orderedCat=models_to_data.keys(), output_dir=output_dir,\n",
    "#                colpal=color_palette, levels=10)\n",
    "# plt.suptitle(\"PCA Comparison\")\n",
    "# plt.savefig(os.path.join(output_dir, \"PCA.jpg\"))\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"* Computing and plotting LD...\")\n",
    "#### Compute correlation between all pairs of SNPs for each generated/real dataset\n",
    "\n",
    "model_names = models_to_data.keys()\n",
    "hcor_snp = dict()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    print(model_name)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Catch warnings due to fixed sites in dataset (the correlation value will be np.nan for pairs involving these sites)\n",
    "        hcor_snp[model_name] = np.corrcoef(datasets[model_name], rowvar=False) ** 2  # r2\n",
    "\n",
    "_, region_len, snps_on_same_chrom = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", region_len_only=True,\n",
    "                                             kept_preprocessing=model_keep_all_snps['Real'])\n",
    "\n",
    "nbins = 100\n",
    "logscale = True\n",
    "bins = nbins\n",
    "binsPerDist = nbins\n",
    "if logscale: binsPerDist = np.logspace(np.log(1), np.log(region_len), nbins)\n",
    "\n",
    "# Compute LD binned by distance\n",
    "# Take only sites that are SNPs in all datasets (intersect)\n",
    "# (eg intersection of SNPs in Real, SNPs in GAN, SNPs in RBM etc)\n",
    "# -> Makes sense only if there is a correspondence between sites\n",
    "\n",
    "binnedLD = dict()\n",
    "binnedPerDistLD = dict()\n",
    "kept_snp = ~is_fixed\n",
    "n_kept_snp = np.sum(kept_snp)\n",
    "realdist = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", kept_preprocessing=model_keep_all_snps['Real'],\n",
    "                    kept_snp=kept_snp)[0]\n",
    "mat = hcor_snp['Real']\n",
    "# filter and flatten\n",
    "flatreal = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "isnanReal = np.isnan(flatreal)\n",
    "i = 1\n",
    "plt.figure(figsize=(10, len(hcor_snp) * 5))\n",
    "\n",
    "for model_name, mat in hcor_snp.items():\n",
    "    flathcor = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "    isnan = np.isnan(flathcor)\n",
    "    curr_dist = realdist\n",
    "\n",
    "    # For each dataset LD pairs are stratified by SNP distance and cut into 'nbins' bins\n",
    "    # bin per SNP distance\n",
    "    ld = binned_statistic(curr_dist[~isnan], flathcor[~isnan], statistic='mean', bins=binsPerDist)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)  # so that empty bins do not raise a warning\n",
    "        binnedPerDistLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                                    'LD': ld.statistic,\n",
    "                                                    # 'sd': binned_statistic(curr_dist[~isnan], flathcor[~isnan], statistic = 'std', bins=binsPerDist).statistic,\n",
    "                                                    'sem': binned_statistic(curr_dist[~isnan], flathcor[~isnan],\n",
    "                                                                            statistic=sem,\n",
    "                                                                            bins=binsPerDist).statistic,\n",
    "                                                    'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "    # For each dataset LD pairs are stratified by LD values in Real and cut into 'nbins' bins\n",
    "    # binnedLD contains the average, std of LD values in each bin\n",
    "    isnan = np.isnan(flathcor) | np.isnan(flatreal)\n",
    "    ld = binned_statistic(flatreal[~isnan], flathcor[~isnan], statistic='mean', bins=bins)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)  # so that empty bins do not raise a warning\n",
    "        binnedLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                             'LD': ld.statistic,\n",
    "                                             'sd': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                    statistic='std',\n",
    "                                                                    bins=bins).statistic,\n",
    "                                             'sem': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                     statistic=sem,\n",
    "                                                                     bins=bins).statistic,\n",
    "                                             'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "    # Plotting quantiles ?\n",
    "    plotregquant(x=flatreal, y=flathcor,\n",
    "                 keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "                 step=0.05,\n",
    "                 ax=plt.subplot(len(hcor_snp), 2, i))\n",
    "    i += 1\n",
    "    plt.title(f'Quantiles LD {model_name} vs Real')\n",
    "\n",
    "    # removing nan values and subsampling before doing the regression to have a reasonnable number of points\n",
    "    isnanInter = isnanReal | isnan\n",
    "    keepforplotreg = random.sample(list(np.where(~isnanInter)[0]), number_of_samples)\n",
    "    plotreg(x=flatreal[keepforplotreg], y=flathcor[keepforplotreg],\n",
    "            keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "            ax=plt.subplot(len(hcor_snp), 2, i))\n",
    "    i += 1\n",
    "    plt.title(f'LD {model_name} vs Real')\n",
    "plt.savefig(os.path.join(output_dir, \"LD_generated_vs_real_intersectSNP.pdf\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import binned_statistic, sem\n",
    "import warnings\n",
    "\n",
    "\n",
    "def compute_and_plot_ld(real_data, synthetic_data, output_dir):\n",
    "    model_names = synthetic_data.keys()\n",
    "    hcor_snp = dict()\n",
    "\n",
    "    for model_name in model_names:\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            hcor_snp[model_name] = np.corrcoef(real_data[model_name], rowvar=False) ** 2  # r2\n",
    "\n",
    "    _, region_len, snps_on_same_chrom = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", region_len_only=True,\n",
    "                                                 kept_preprocessing=real_data)\n",
    "\n",
    "    nbins = 100\n",
    "    logscale = True\n",
    "    bins = nbins\n",
    "    binsPerDist = nbins\n",
    "    if logscale:\n",
    "        binsPerDist = np.logspace(np.log(1), np.log(region_len), nbins)\n",
    "\n",
    "    binnedLD = dict()\n",
    "    binnedPerDistLD = dict()\n",
    "    realdist = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", kept_preprocessing=real_data,\n",
    "                        kept_snp='all')[0]\n",
    "    mat = hcor_snp['Real']\n",
    "    flatreal = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "    isnanReal = np.isnan(flatreal)\n",
    "    i = 1\n",
    "\n",
    "    plt.figure(figsize=(10, len(hcor_snp) * 5))\n",
    "\n",
    "    for model_name, mat in hcor_snp.items():\n",
    "        flathcor = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "        isnan = np.isnan(flathcor)\n",
    "        curr_dist = realdist\n",
    "\n",
    "        ld = binned_statistic(curr_dist[~isnan], flathcor[~isnan], statistic='mean', bins=binsPerDist)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            binnedPerDistLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                                        'LD': ld.statistic,\n",
    "                                                        'sem': binned_statistic(curr_dist[~isnan], flathcor[~isnan],\n",
    "                                                                                statistic=sem,\n",
    "                                                                                bins=binsPerDist).statistic,\n",
    "                                                        'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "        isnan = np.isnan(flathcor) | np.isnan(flatreal)\n",
    "        ld = binned_statistic(flatreal[~isnan], flathcor[~isnan], statistic='mean', bins=bins)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            binnedLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                                 'LD': ld.statistic,\n",
    "                                                 'sd': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                        statistic='std',\n",
    "                                                                        bins=bins).statistic,\n",
    "                                                 'sem': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                         statistic=sem,\n",
    "                                                                         bins=bins).statistic,\n",
    "                                                 'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "        # Plotting quantiles ?\n",
    "        plotregquant(x=flatreal, y=flathcor,\n",
    "                     keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "                     step=0.05,\n",
    "                     ax=plt.subplot(len(hcor_snp), 2, i))\n",
    "        i += 1\n",
    "        plt.title(f'Quantiles LD {model_name} vs Real')\n",
    "\n",
    "        # removing nan values and subsampling before doing the regression to have a reasonnable number of points\n",
    "        isnanInter = isnanReal | isnan\n",
    "        keepforplotreg = random.sample(list(np.where(~isnanInter)[0]), number_of_samples)\n",
    "        plotreg(x=flatreal[keepforplotreg], y=flathcor[keepforplotreg],\n",
    "                keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "                ax=plt.subplot(len(hcor_snp), 2, i))\n",
    "        i += 1\n",
    "        plt.title(f'LD {model_name} vs Real')\n",
    "    plt.savefig(os.path.join(output_dir, \"LD_generated_vs_real_intersectSNP.pdf\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def plot_ld_compression(array1, array2):\n",
    "#     # Check if the arrays have the same number of columns\n",
    "#     if array1.shape[1] != array2.shape[1]:\n",
    "#         raise ValueError(\"Arrays must have the same number of columns.\")\n",
    "#\n",
    "#     # Resize arrays to have the same number of rows\n",
    "#     min_rows = min(array1.shape[0], array2.shape[0])\n",
    "#     array1 = array1[:min_rows, :]\n",
    "#     array2 = array2[:min_rows, :]\n",
    "#\n",
    "#     # Create a compressed array\n",
    "#     compressed_array = np.zeros(array1.shape)\n",
    "#\n",
    "#     # Iterate through each element in the arrays\n",
    "#     for i in range(array1.shape[0]):\n",
    "#         for j in range(array1.shape[1]):\n",
    "#             # Check if the genotypes are the same\n",
    "#             if array1[i, j] == array2[i, j]:\n",
    "#                 compressed_array[i, j] = array1[i, j]\n",
    "#\n",
    "#     # Calculate the difference between the original and compressed arrays\n",
    "#     diff_array = array1 - compressed_array\n",
    "#\n",
    "#     # Set up the plot layout\n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "#\n",
    "#     # Plot the original Array 1\n",
    "#     img1 = axes[0].imshow(array1, cmap='coolwarm', aspect='auto', vmin=0, vmax=1)\n",
    "#     axes[0].set_title('Original Array')\n",
    "#     axes[0].axis('off')\n",
    "#\n",
    "#     # Plot the compressed array\n",
    "#     img2 = axes[1].imshow(compressed_array, cmap='coolwarm', aspect='auto', vmin=0, vmax=1)\n",
    "#     axes[1].set_title('Compressed Array')\n",
    "#     axes[1].axis('off')\n",
    "#\n",
    "#     # Plot the difference between the original and compressed arrays\n",
    "#     img3 = axes[2].imshow(diff_array, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "#     axes[2].set_title('Difference')\n",
    "#     axes[2].axis('off')\n",
    "#\n",
    "#     # Add a colorbar for the difference plot\n",
    "#     cbar = fig.colorbar(img3, ax=axes[2])\n",
    "#     cbar.set_label('Difference')\n",
    "#\n",
    "#     # Adjust the spacing between subplots\n",
    "#     plt.tight_layout()\n",
    "#\n",
    "#     # Display the plot\n",
    "#     plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# def plot_ld_generated_vs_real_intersect_snp(real_data, synthetic_data):\n",
    "#     # Calculate the intersection of SNP values\n",
    "#     intersect_snp = np.sum(real_data == synthetic_data, axis=1)\n",
    "#\n",
    "#     # Calculate the LD between real and synthetic datasets\n",
    "#     ld = np.corrcoef(real_data.T, synthetic_data.T)\n",
    "#\n",
    "#     # Plotting\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.scatter(range(len(intersect_snp)), intersect_snp, c=ld[1:, 0], cmap='cool', alpha=0.7)\n",
    "#     plt.xlabel('SNP Index')\n",
    "#     plt.ylabel('Intersection of SNP Values')\n",
    "#     plt.title('LD: Generated vs Real - Intersect SNP')\n",
    "#     cbar = plt.colorbar()\n",
    "#     cbar.set_label('LD Correlation')\n",
    "#     plt.savefig('LD_generated_vs_real_intersectSNP.jpg')\n",
    "#     plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot_ld_generated_vs_real_intersect_snp(full_datasets['Real'], full_datasets['WGAN'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot_ld_compression(full_datasets['Real'], full_datasets['Genome-AC-GAN By National Population'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "line_styles = ['solid', 'dashdot', 'dotted']\n",
    "scores = []\n",
    "real_bld = binnedPerDistLD['Real'].LD.values[~np.isnan(binnedPerDistLD['Real'].LD.values)]\n",
    "# Calculate the absolute difference from the \"Real\" line\n",
    "for index, (model_name, bld) in enumerate(binnedPerDistLD.items()):\n",
    "    style_index = index % len(line_styles)\n",
    "    line_style = line_styles[style_index]\n",
    "    r2 = round(r2_score(real_bld, bld.LD.values[~np.isnan(bld.LD.values)]), 3)\n",
    "    rmse = round(np.sqrt(mean_squared_error(real_bld, bld.LD.values[~np.isnan(bld.LD.values)])), 3)\n",
    "    plt.errorbar(\n",
    "        bld.bin_edges.values, bld.LD.values, bld['sem'].values,\n",
    "        label=r\"$\\mathbf{\" + model_name + \"}$  RMSE = \" + str(rmse) + \", R-squared = \" + str(r2),\n",
    "        alpha=0.8, linewidth=3, linestyle=line_style\n",
    "    )\n",
    "\n",
    "# plt.title(\"Binned LD +/- 1 sem\")\n",
    "if logscale:\n",
    "    plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel(\"Distance between SNPs (bp) [Left bound of distance bin]\", fontsize=15)\n",
    "plt.ylabel(\"Average LD in bin\", fontsize=15)\n",
    "plt.legend(fontsize='large', loc=\"upper right\")\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, \"correlation_vs_dist_intersectSNP.jpg\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axes object\n",
    "fig, axes = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the data for each model\n",
    "for model_name, bld in binnedPerDistLD.items():\n",
    "    plt.errorbar(bld.bin_edges.values, bld.LD.values, bld['sem'].values, label=model_name, alpha=.65,\n",
    "                 linewidth=3, color=color_palette[model_name])\n",
    "\n",
    "# Add a title to the plot\n",
    "plt.title(\"Binned LD +/- 1 sem\")\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel(\"Distance between SNPs (bp) [Left bound of distance bin]\")\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel(\"Average LD in bin\")\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(output_dir, \"correlation_vs_dist_intersectSNP.pdf\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For each dataset LD pairs were stratified by LD values in Real, cut into nbins bins\n",
    "# binnedLD contains the average LD in each bin\n",
    "# Plot generated average LD as a function of the real average LD in the bins\n",
    "plt.figure(figsize=(10, 10))\n",
    "for model_name, bld in binnedLD.items():\n",
    "    plt.errorbar(bld.bin_edges.values, bld.LD.values, bld['sem'].values, label=model_name, alpha=0.8, marker='o')\n",
    "plt.title(\"Binned LD +/- 1 sem\")\n",
    "plt.xlabel(\"Bins (LD in Real)\")\n",
    "plt.ylabel(\"Average LD in bin\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'LD decay.jpg'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Set edges of the region for which to plot LD block matrix (l=0, f='end') for full region\n",
    "# # not used as for now apart from the filename\n",
    "# l_bound = None\n",
    "# r_bound = None\n",
    "# snpcode = \"fullSNP\"\n",
    "# mirror, diff = False, False\n",
    "# outfilename = f\"LD_HEATMAP_{snpcode}_bounds={l_bound}-{r_bound}_mirror={mirror}_diff={diff}.pdf\"\n",
    "# fig = plt.figure(figsize=(10 * len(hcor_snp), 10))\n",
    "# plotLDblock(hcor_snp,\n",
    "#             left=l_bound, right=r_bound,  # None, None -> takes all SNPs\n",
    "#             mirror=mirror, diff=diff,\n",
    "#             is_fixed=is_fixed, is_fixed_dic=is_fixed_dic,\n",
    "#             suptitle_kws={'t': outfilename}\n",
    "#             )\n",
    "# plt.title(outfilename)\n",
    "# plt.savefig(os.path.join(output_dir, outfilename))\n",
    "# plt.show()\n",
    "#\n",
    "# print(\n",
    "#     '****************************************************************\\n*** Computation and plotting LD DONE. Figures saved in {} ***\\n****************************************************************'.format(\n",
    "#         output_dir))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dSS_dic = dict()\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "for cat, mat in datasets.items():\n",
    "    dAB = distance.cdist(mat, mat, 'cityblock')\n",
    "    np.fill_diagonal(dAB, np.Inf)\n",
    "    dSS_dic[cat] = dAB.min(axis=1)\n",
    "    sns.kdeplot(dAB[np.triu_indices(dAB.shape[0], k=1)], linewidth=3, label=cat)  # dSS\n",
    "plt.title(\"Pairwise distance within each dataset\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for cat, d in dSS_dic.items():\n",
    "    sns.kdeplot(dSS_dic[cat], linewidth=3, label=cat)\n",
    "plt.title(\"Minimal pairwise distance within each dataset\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, \"haplo_pairw_distrib_within.pdf\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "haplo = np.concatenate(list(datasets.values())).T  # orientation of scikit allele\n",
    "\n",
    "outFilePrefix = ''\n",
    "# if not ref in model_name_to_input_file.keys(): continue\n",
    "ref = 'Real'\n",
    "print(\"Computing AATS with ref \" + ref)\n",
    "AA, MINDIST = computeAAandDist(\n",
    "    pd.DataFrame(haplo.T),\n",
    "    extra_sample_info.label,\n",
    "    models_to_data.keys(),\n",
    "    refCateg=ref,\n",
    "    saveAllDist=True,\n",
    "    output_dir=output_dir,\n",
    "    outFilePrefix=outFilePrefix)\n",
    "\n",
    "# save AA and MINDIST pd.DataFrame to csv\n",
    "# np.array of all pariwise distances are saved as npz automatically when calling computeAAandDist with saveAllDist=True\n",
    "AA.to_csv(os.path.join(output_dir, f'AA_{ref}.csv.bz2'), index=None)\n",
    "MINDIST.to_csv(os.path.join(output_dir, f'MINDIST_{ref}.csv.bz2'), index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Distribution WITHIN model_namesories\n",
    "W = pd.DataFrame(columns=['stat', 'statistic', 'label', 'comparaison'])\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "model_names = models_to_data.keys()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    subset = (np.load('{}/dist_{}_{}.npz'.format(output_dir, model_name, model_name)))['dist']\n",
    "    if model_name == 'Real':\n",
    "        subsetreal = subset\n",
    "    sns.kdeplot(subset, linewidth=3, label=model_name)\n",
    "\n",
    "    sc = scs.wasserstein_distance(subsetreal, subset)\n",
    "    new_row = pd.DataFrame(\n",
    "        {'stat': ['wasserstein'], 'statistic': [sc], 'label': [model_name], 'comparaison': ['within']})\n",
    "    W = pd.concat([W, new_row], ignore_index=True)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(output_dir, \"distribution_haplotypic_pairwise_diff.jpg\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Distribution WITHIN model_namesories\n",
    "W = pd.DataFrame(columns=['stat', 'statistic', 'label', 'comparaison'])\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(1, 2, 1)\n",
    "model_names = models_to_data.keys()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    subset = (np.load('{}/dist_{}_{}.npz'.format(output_dir, model_name, model_name)))['dist']\n",
    "    if model_names == 'Real':\n",
    "        subsetreal = subset\n",
    "    sns.distplot(subset, hist=False, kde=True,\n",
    "                 kde_kws={'linewidth': 3},  #'bw':.02\n",
    "                 label='{} ({} identical pairs)'.format(model_names, (subset == 0).sum()))\n",
    "\n",
    "    sc = scs.wasserstein_distance(subsetreal, subset)\n",
    "    W = pd.concat([W, pd.DataFrame(\n",
    "        [{'stat': 'wasserstein', 'statistic': sc, 'pvalue': None, 'label': model_name, 'comparaison': 'between'}])],\n",
    "                  ignore_index=True)\n",
    "\n",
    "plt.title(\"Distribution of haplotypic pairwise difference within each dataset\")\n",
    "plt.legend()\n",
    "#plt.savefig(outDir+\"haplo_pairw_distrib_within_{}_simplify.pdf\".format(\"-\".join(categ)))\n",
    "subsetreal = None\n",
    "\n",
    "#### Distribution BETWEEN categories\n",
    "plt.subplot(1, 2, 2)\n",
    "model_names = models_to_data.keys()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    subset = (np.load('{}/dist_{}_{}.npz'.format(output_dir, model_name, model_name)))['dist']\n",
    "    if model_name == 'Real':\n",
    "        subsetreal = subset\n",
    "    sns.distplot(subset, hist=False, kde=True,\n",
    "                 kde_kws={'linewidth': 3},  #'bw':.02\n",
    "                 label='{} vs {} ({} identical pairs)'.format(model_name, 'Real', (subset == 0).sum()))\n",
    "\n",
    "    sc = scs.wasserstein_distance(subsetreal, subset)\n",
    "    W = pd.concat([W, pd.DataFrame(\n",
    "        [{'stat': 'wasserstein', 'statistic': sc, 'pvalue': None, 'label': model_name, 'comparaison': 'between'}])])\n",
    "\n",
    "plt.title(\"Distribution of haplotypic pairwise difference between datasets\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, \"haplo_pairw_distrib.pdf\"))\n",
    "\n",
    "scores = pd.concat([W])\n",
    "\n",
    "print(W)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MINDIST.to_csv(os.path.join(output_dir, \"MINDIST.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_score_distributions(df):\n",
    "    # Create a figure with three subplots, one for each score type\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 15))\n",
    "\n",
    "    # Set the column names for the score types\n",
    "    score_types = ['dTS', 'dST', 'dSS']\n",
    "\n",
    "    # Set the colors for each model\n",
    "    model_colors = sns.color_palette('Set1', n_colors=len(df['cat'].unique()))\n",
    "\n",
    "    # Create a dictionary to store the model names and their corresponding colors\n",
    "    model_color_dict = dict(zip(df['cat'].unique(), model_colors))\n",
    "\n",
    "    # Iterate over the score types\n",
    "    for i, score_type in enumerate(score_types):\n",
    "        # Select the data for the current score type\n",
    "        data = df[['cat', score_type]]\n",
    "\n",
    "        # Melt the data to transform it into long format\n",
    "        data_melted = data.explode(score_type).reset_index(drop=True)\n",
    "\n",
    "        # Plot the distribution for each model\n",
    "        for model in df['cat'].unique():\n",
    "            model_data = data_melted[data_melted['cat'] == model]\n",
    "            color = model_color_dict[model]\n",
    "\n",
    "            sns.histplot(data=model_data, x=score_type, element='step', stat='density',\n",
    "                         common_norm=False, fill=False, kde=True,\n",
    "                         ax=axes[i], color=color, label=model)\n",
    "\n",
    "        # Set plot title and labels\n",
    "        axes[i].set_title(f'Distribution of {score_type}')\n",
    "        axes[i].set_xlabel('Score')\n",
    "        axes[i].set_ylabel('Density')\n",
    "\n",
    "        # Set legend\n",
    "        axes[i].legend(title='Model', loc='upper right')\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_score_distributions(MINDIST)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_score_distributions(df, score_name):\n",
    "    flattened_df = df[['cat', score_name]].explode(score_name).reset_index(drop=True)\n",
    "\n",
    "    # Reorder the unique model names with 'Real' at the front\n",
    "    unique_models = list(flattened_df[\"cat\"].unique())\n",
    "    unique_models.remove('Real')\n",
    "    unique_models.append('Real')\n",
    "    color_palette['Real'] = 'black'\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Iterate over the reordered unique model names and plot the distribution for each\n",
    "    for model_name in unique_models:\n",
    "        if model_name == 'Real':\n",
    "            sns.kdeplot(data=flattened_df[flattened_df[\"cat\"] == model_name], x=score_name, label=model_name,\n",
    "                        fill=True, common_norm=False, alpha=0.6, color='black')\n",
    "        else:\n",
    "            sns.kdeplot(data=flattened_df[flattened_df[\"cat\"] == model_name], x=score_name, label=model_name,\n",
    "                        common_norm=False, alpha=1, linewidth=5)\n",
    "\n",
    "    plt.xlabel(score_name)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend(title=\"Model Name\", loc=\"upper right\")\n",
    "    plt.title(f\"Distribution of {score_name} by Model\")\n",
    "    plt.savefig(os.path.join(output_dir, score_name + \"_DISTRIBUTIONS.jpg\"))\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_score_distributions(MINDIST, 'dST')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_score_distributions(MINDIST, 'dTS')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_score_distributions(MINDIST, 'dSS')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W = pd.DataFrame(columns=['stat', 'statistic', 'label', 'comparaison'])\n",
    "for model_name in models_to_data.keys():\n",
    "    for method in ['dTS', 'dST', 'dSS']:\n",
    "        real = MINDIST[method][MINDIST.cat == 'Real'][0]\n",
    "        sc = scs.wasserstein_distance(real, MINDIST[method][MINDIST.cat == model_name].values[0])\n",
    "        new_row = pd.DataFrame({'stat': ['wasserstein'], 'statistic': [sc],\n",
    "                                'label': [model_name], 'comparaison': [method]})\n",
    "        W = pd.concat([W, new_row], ignore_index=True)\n",
    "scores = pd.concat([W])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = pd.concat([scores, W])\n",
    "scores.to_csv(os.path.join(output_dir, \"scores_pairwise_distances.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(1.5 * len(model_names), 6))\n",
    "\n",
    "sns.barplot(x='Cat', y='Value', hue='Variable', palette=sns.color_palette('colorblind'),\n",
    "            data=(AA.drop(columns=['PrivacyLoss', 'ref'], errors='ignore')).melt(id_vars='cat').rename(\n",
    "                columns=str.title))\n",
    "plt.axhline(0.5, color='black')\n",
    "if 'Real_test' in AA.cat.values:\n",
    "    plt.axhline(np.float(AA[AA.cat == 'Real_test'].AATS), color=sns.color_palette()[0], ls='--')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.title(\"Nearest Neighbor Adversarial Accuracy on training (AATS) and its components\")\n",
    "plt.savefig(os.path.join(output_dir, \"AATS_scores.pdf\"))\n",
    "\n",
    "Test = '_Test2'\n",
    "Train = ''  # means Training set is Real\n",
    "dfPL = plotPrivacyLoss(Train, Test, output_dir, color_palette, color_palette)\n",
    "\n",
    "Test = '_Test2'\n",
    "Train = '_Test1'\n",
    "dfPL = plotPrivacyLoss(Train, Test, output_dir, color_palette, color_palette)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_counts(haplosubset, points):\n",
    "    counts = np.unique(\n",
    "        np.apply_along_axis(\n",
    "            lambda x: ''.join(map(str, x[points])),\n",
    "            # lambda x: ''.join([str(x[p]) for p in points]),\n",
    "            0, haplosubset),\n",
    "        return_counts=True)\n",
    "    return (counts)\n",
    "\n",
    "\n",
    "def get_frequencies(counts):\n",
    "    l = len(counts[0][0])  # haplotype length\n",
    "    nind = np.sum(counts[1])\n",
    "    f = np.zeros(shape=[2] * l)\n",
    "    for i, allele in enumerate(counts[0]):\n",
    "        f[tuple(map(int, allele))] = counts[1][i] / nind\n",
    "    return f\n",
    "\n",
    "\n",
    "def three_points_cor(haplosubset, out='all'):\n",
    "    F = dict()\n",
    "    for points in [[0], [1], [2], [0, 1], [0, 2], [1, 2], [0, 1, 2]]:\n",
    "        strpoints = ''.join(map(str, points))\n",
    "        F[strpoints] = get_frequencies(\n",
    "            get_counts(haplosubset, points)\n",
    "        )\n",
    "\n",
    "    cors = [\n",
    "        F['012'][a, b, c] - F['01'][a, b] * F['2'][c] - F['12'][b, c] * F['0'][a] - F['02'][a, c] * F['1'][b] + 2 *\n",
    "        F['0'][a] * F['1'][b] * F['2'][c] for a, b, c in itertools.product(*[[0, 1]] * 3)]\n",
    "    if out == 'mean':\n",
    "        return (np.mean(cors))\n",
    "    if out == 'max':\n",
    "        return (np.max(np.abs(cors)))\n",
    "    if out == 'all':\n",
    "        return (cors)\n",
    "    return (ValueError(f\"out={out} not recognized\"))\n",
    "\n",
    "\n",
    "# def mult_three_point_cor(haplo, extra_sample_info, model_name, picked_three_points):\n",
    "#    return [three_points_cor(haplo[np.ix_(snps,extra_sample_info.label==model_name)], out='all') for snps in picked_three_points]\n",
    "\n",
    "# set the seed so that the same real individual are subsampled (when needed)\n",
    "# to ensure consistency of the scores when adding a new model or a new sumstat\n",
    "np.random.seed(3)\n",
    "random.seed(3)\n",
    "\n",
    "# Compute 3 point correlations results for different datasets and different distances between SNPs\n",
    "\n",
    "# pick distance between SNPs at which 3point corr will be computed\n",
    "# (defined in nb of snps)\n",
    "# a gap of -9 means that snp triplets are chosen completely at random (not predefined distance)\n",
    "# for each category we randomly pick 'nsamplesets' triplets\n",
    "\n",
    "# if datasets have different nb of snps, for convenience we will sample\n",
    "# slightly more at the beginning of the chunk\n",
    "\n",
    "gap_vec = [1, 4, 16, 64, 256, 512, 1024, -9]\n",
    "nsamplesets = 1000\n",
    "min_nsnp = min([dat.shape[1] for dat in datasets.values()])\n",
    "cors_meta = dict()\n",
    "for gap in gap_vec:\n",
    "    print(f'\\n gap={gap} SNPs', end=' ')\n",
    "    if gap < 0:\n",
    "        # pick 3 random snps\n",
    "        picked_three_points = [random.sample(range(min_nsnp), 3) for _ in range(nsamplesets)]\n",
    "    else:\n",
    "        try:\n",
    "            # pick 3 successive snps spearated by 'gap' SNPs\n",
    "            step = gap + 1\n",
    "            picked_three_points = [np.asarray(random.sample(range(min_nsnp - 2 * step), 1)) + [0, step, 2 * step]\n",
    "                                   for _\n",
    "                                   in range(nsamplesets)]\n",
    "        except:\n",
    "            continue  # if there were not enough SNPs for this gap\n",
    "    cors = dict()\n",
    "\n",
    "    for model_name in datasets.keys():\n",
    "        print(model_name, end=' ')\n",
    "        # cors[model_name]=[three_points_cor(haplo[np.ix_(snps,extra_sample_info.label==model_name)], out='all') for snps in picked_three_points]\n",
    "        cors[model_name] = [three_points_cor(datasets[model_name][:, snps].T, out='all') for snps in\n",
    "                            picked_three_points]\n",
    "\n",
    "    cors_meta[gap] = cors.copy()\n",
    "\n",
    "# print(cors_meta)\n",
    "\n",
    "with open(os.path.join(output_dir, \"3pointcorr.pkl\"), \"wb\") as outfile:\n",
    "    pickle.dump(cors_meta, outfile)\n",
    "\n",
    "# Plot 3-point correlations results\n",
    "\n",
    "plt.figure(figsize=(2 * len(cors_meta), 7))\n",
    "# plt.figure(figsize=(figwi,figwi/2))\n",
    "for i, gap in enumerate((cors_meta).keys()):\n",
    "    ax = plt.subplot(2, int(np.ceil(len(cors_meta) / 2)), int(i) + 1)\n",
    "    cors = cors_meta[gap]\n",
    "    real = list(np.array(cors['Real']).flat)\n",
    "    lims = [np.min(real), np.max(real)]\n",
    "    for key, val in cors.items():\n",
    "        if key == 'Real': continue\n",
    "        val = list(np.array(val).flat)\n",
    "        plotreg(x=real, y=val, keys=['Real', key],\n",
    "                statname='Correlation', col=color_palette[key], ax=ax)\n",
    "    if gap < 0:\n",
    "        plt.title('3-point corr for random SNPs')\n",
    "    else:\n",
    "        plt.title(f'3-point corr for SNPs sep. by {gap} SNPs')\n",
    "\n",
    "    plt.legend(fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, '3point_correlations.jpg'), dpi=300)  # can pick one of the format\n",
    "\n",
    "# Same plot with axes limit fixed to (-0.1,0.1) for the sake of comparison\n",
    "\n",
    "plt.figure(figsize=(4 * len(cors_meta), 14))\n",
    "# plt.figure(figsize=(figwi,figwi/2))\n",
    "for i, gap in enumerate((cors_meta).keys()):\n",
    "    ax = plt.subplot(2, int(np.ceil(len(cors_meta) / 2)), int(i) + 1)\n",
    "    cors = cors_meta[gap]\n",
    "    real = list(np.array(cors['Real']).flat)\n",
    "    lims = [np.min(real), np.max(real)]\n",
    "    for key, val in cors.items():\n",
    "        if key == 'Real': continue\n",
    "        val = list(np.array(val).flat)\n",
    "        plotreg(x=real, y=val, keys=['Real', key],\n",
    "                statname='Correlation', col=color_palette[key], ax=ax)\n",
    "        ax.set_xlim((-.1, .1))\n",
    "        ax.set_ylim((-.1, .1))\n",
    "\n",
    "    if gap < 0:\n",
    "        plt.title('3-point corr for random SNPs')\n",
    "    else:\n",
    "        plt.title(f'3-point corr for SNPs sep. by {gap} SNPs')\n",
    "\n",
    "    plt.legend(fontsize='small')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, '3point_correlations_fixlim.pdf'), dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
