{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.stats import sem\n",
    "\n",
    "from utils.util import *\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "    \"Real\": {\n",
    "        \"path\": \"resource/10K_SNP_1000G_real.hapt\",\n",
    "        \"color\": \"gray\"\n",
    "    },\n",
    "    \"GAN_prev\": {\n",
    "        \"path\": \"fake_genotypes_sequences/preview_sequences/10K_SNP_GAN_AG_10800Epochs.hapt\",\n",
    "        \"color\": \"blue\"\n",
    "    },\n",
    "    \"RBM_prev\": {\n",
    "        \"path\": \"fake_genotypes_sequences/preview_sequences/10K_RBM.hapt\",\n",
    "        \"color\": \"red\"\n",
    "    },\n",
    "    \"RBM_new\": {\n",
    "        \"path\": \"fake_genotypes_sequences/preview_sequences/10K_SNP_RBM_AG_1050epochs.hapt\",\n",
    "        \"color\": \"orange\"\n",
    "    },\n",
    "    \"WGAN\": {\n",
    "        \"path\": \"fake_genotypes_sequences/preview_sequences/10K_SNP_RBM_AG_1050epochs.hapt\",\n",
    "        \"color\": \"purple\"\n",
    "    },\n",
    "    \"DEFAULT GS-AC-GAN\": {\n",
    "        \"path\": \"fake_genotypes_sequences/new_sequences/default_gs-ac-gan/genotypes.hapt\",\n",
    "        \"color\": \"brown\"\n",
    "    },\n",
    "    \"F1 WITH PENALTY GS-AC-GAN\": {\n",
    "        \"path\": \"fake_genotypes_sequences/new_sequences/f1_score_test/genotypes.hapt\",\n",
    "        \"color\": \"green\"\n",
    "    },\n",
    "    \"SUB F1 WITH PENALTY GS-AC-GAN, \": {\n",
    "        \"path\": \"fake_genotypes_sequences/new_sequences/f1_score_sub_pop/genotypes.hapt\",\n",
    "        \"color\": \"blue\"\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUMBER_OF_SAMPLES = 500\n",
    "output_dir = os.environ.get(\"output_dir\", DEFAULT_EXPERIMENT_OUTPUT_DIR)\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "compute_AATS = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name_to_input_file, model_name_to_color, color_palette = init_analysis_args(output_dir, models_to_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extra_sample_info, sample_info, datasets, transformations, model_keep_all_snps = load_analysis_data(number_of_samples=NUMBER_OF_SAMPLES, model_name_to_input_file=model_name_to_input_file)\n",
    "sum_alleles_by_position, allele_frequency, is_fixed = build_allele_frequency(datasets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figwi = 12\n",
    "plt.figure(figsize=(15, 5 * len(model_name_to_input_file.keys())))\n",
    "l, c = len(model_name_to_input_file.keys()) - 1, 2\n",
    "plt.figure(figsize=(figwi * c / 4, figwi * l / 4))\n",
    "win = 1\n",
    "for i, model_name in enumerate(model_name_to_input_file.keys()):\n",
    "    if model_name == 'Real': continue\n",
    "    plt.subplot(l, c, win)\n",
    "    win += 1\n",
    "    plt.plot(allele_frequency['Real'][(sum_alleles_by_position[model_name] == 0)], alpha=1, marker='.', lw=0)\n",
    "    plt.ylabel(\"Allele frequency in Real\")\n",
    "    plt.title(\"Real frequency of alleles \\n absent from {}\".format(model_name))\n",
    "    plt.subplot(l, c, win)\n",
    "    win += 1\n",
    "    plt.hist(allele_frequency['Real'][(sum_alleles_by_position[model_name] == 0)], alpha=1)\n",
    "    plt.title(\"Hist real freq of alleles \\n absent from {}\".format(model_name))\n",
    "\n",
    "plt.suptitle(\"Plotting allele frequency characteristics \\n\\n\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"RealAC_for_0fixed_sites.pdf\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting Allele frequencies in Generated vs Real\n",
    "# below a certain real frequency (here set to 0.2 ie 20%)\n",
    "l, c = np.ceil(len(allele_frequency) / 3), 3\n",
    "plt.figure(figsize=(figwi, figwi * l / c))\n",
    "maf = 0.2\n",
    "keep = (allele_frequency['Real'] <= maf)\n",
    "for i, (model_name, val) in enumerate(allele_frequency.items()):\n",
    "    ax = plt.subplot(int(l), c, i + 1)\n",
    "    plotreg(x=allele_frequency['Real'][keep], y=val[keep],\n",
    "            keys=['Real', model_name], statname=\"Allele frequency\",\n",
    "            col=color_palette[model_name], ax=ax)\n",
    "    plt.title(f'{model_name} vs Real')\n",
    "plt.suptitle(f'AF below {maf} in Real \\n\\n')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'AC_generated_vs_Real_zoom.pdf'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting Allele frequencies in Generated vs Real\n",
    "l, c = np.ceil(len(allele_frequency) / 3), 3\n",
    "plt.figure(figsize=(figwi, figwi * l / c))\n",
    "for i, (model_name, val) in enumerate(allele_frequency.items()):\n",
    "    ax = plt.subplot(int(l), 3, i + 1)\n",
    "    plotreg(x=allele_frequency['Real'], y=val,\n",
    "            keys=['Real', model_name], statname=\"Allele frequency\",\n",
    "            col=color_palette[model_name], ax=ax)\n",
    "    plt.title(f'Allele Frequencies {model_name} vs Real')\n",
    "plt.suptitle(f'Allele Frequencies vs Real \\n\\n')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'AC_generated_vs_Real.pdf'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "score_list = []\n",
    "number_of_components = 6  # change to compute more PCs\n",
    "\n",
    "method_name = \"Combined PCA\"\n",
    "print(f'Computing {method_name} ...')\n",
    "pca = PCA(n_components=number_of_components)\n",
    "pcs = pca.fit_transform(\n",
    "    np.concatenate(list(datasets.values()))\n",
    ")\n",
    "pcdf = pd.DataFrame(pcs, columns=[\"PC{}\".format(x + 1) for x in np.arange(pcs.shape[1])])\n",
    "pcdf[\"label\"] = extra_sample_info.label.astype('category')\n",
    "plotPCAallfigs(pcdf, method_name, orderedCat=model_name_to_input_file.keys(), output_dir=output_dir,\n",
    "               colpal=color_palette)\n",
    "plt.suptitle(\"PCA Comparison\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"* Computing and plotting LD...\")\n",
    "#### Compute correlation between all pairs of SNPs for each generated/real dataset\n",
    "\n",
    "model_names = model_name_to_input_file.keys()\n",
    "hcor_snp = dict()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    print(model_name)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Catch warnings due to fixed sites in dataset (the correlation value will be np.nan for pairs involving these sites)\n",
    "        hcor_snp[model_name] = np.corrcoef(datasets[model_name], rowvar=False) ** 2  # r2\n",
    "\n",
    "_, region_len, snps_on_same_chrom = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", region_len_only=True,\n",
    "                                             kept_preprocessing=model_keep_all_snps['Real'])\n",
    "\n",
    "nbins = 50\n",
    "logscale = True\n",
    "bins = nbins\n",
    "binsPerDist = nbins\n",
    "if logscale: binsPerDist = np.logspace(np.log(1), np.log(region_len), nbins)\n",
    "\n",
    "# Compute LD binned by distance\n",
    "# Take only sites that are SNPs in all datasets (intersect)\n",
    "# (eg intersection of SNPs in Real, SNPs in GAN, SNPs in RBM etc)\n",
    "# -> Makes sense only if there is a correspondence between sites\n",
    "\n",
    "binnedLD = dict()\n",
    "binnedPerDistLD = dict()\n",
    "kept_snp = ~is_fixed\n",
    "n_kept_snp = np.sum(kept_snp)\n",
    "realdist = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", kept_preprocessing=model_keep_all_snps['Real'],\n",
    "                    kept_snp=kept_snp)[0]\n",
    "mat = hcor_snp['Real']\n",
    "# filter and flatten\n",
    "flatreal = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "isnanReal = np.isnan(flatreal)\n",
    "i = 1\n",
    "plt.figure(figsize=(10, len(hcor_snp) * 5))\n",
    "\n",
    "for model_name, mat in hcor_snp.items():\n",
    "    flathcor = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "    isnan = np.isnan(flathcor)\n",
    "    curr_dist = realdist\n",
    "\n",
    "    # For each dataset LD pairs are stratified by SNP distance and cut into 'nbins' bins\n",
    "    # bin per SNP distance\n",
    "    ld = binned_statistic(curr_dist[~isnan], flathcor[~isnan], statistic='mean', bins=binsPerDist)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)  # so that empty bins do not raise a warning\n",
    "        binnedPerDistLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                                    'LD': ld.statistic,\n",
    "                                                    # 'sd': binned_statistic(curr_dist[~isnan], flathcor[~isnan], statistic = 'std', bins=binsPerDist).statistic,\n",
    "                                                    'sem': binned_statistic(curr_dist[~isnan], flathcor[~isnan],\n",
    "                                                                            statistic=sem,\n",
    "                                                                            bins=binsPerDist).statistic,\n",
    "                                                    'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "    # For each dataset LD pairs are stratified by LD values in Real and cut into 'nbins' bins\n",
    "    # binnedLD contains the average, std of LD values in each bin\n",
    "    isnan = np.isnan(flathcor) | np.isnan(flatreal)\n",
    "    ld = binned_statistic(flatreal[~isnan], flathcor[~isnan], statistic='mean', bins=bins)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)  # so that empty bins do not raise a warning\n",
    "        binnedLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                             'LD': ld.statistic,\n",
    "                                             'sd': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                    statistic='std',\n",
    "                                                                    bins=bins).statistic,\n",
    "                                             'sem': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                     statistic=sem,\n",
    "                                                                     bins=bins).statistic,\n",
    "                                             'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "    # Plotting quantiles ?\n",
    "    plotregquant(x=flatreal, y=flathcor,\n",
    "                 keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "                 step=0.05,\n",
    "                 ax=plt.subplot(len(hcor_snp), 2, i))\n",
    "    i += 1\n",
    "    plt.title(f'Quantiles LD {model_name} vs Real')\n",
    "\n",
    "    # removing nan values and subsampling before doing the regression to have a reasonnable number of points\n",
    "    isnanInter = isnanReal | isnan\n",
    "    keepforplotreg = random.sample(list(np.where(~isnanInter)[0]), NUMBER_OF_SAMPLES)\n",
    "    plotreg(x=flatreal[keepforplotreg], y=flathcor[keepforplotreg],\n",
    "            keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "            ax=plt.subplot(len(hcor_snp), 2, i))\n",
    "    i += 1\n",
    "    plt.title(f'LD {model_name} vs Real')\n",
    "plt.savefig(os.path.join(output_dir, \"LD_generated_vs_real_intersectSNP.pdf\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if snps_on_same_chrom:  # (position_fname['Real']!=\"1kg_real/805snps.legend\"):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for model_name, bld in binnedPerDistLD.items():\n",
    "        plt.errorbar(bld.bin_edges.values, bld.LD.values, bld['sem'].values, label=model_name, alpha=.65,\n",
    "                     linewidth=3)\n",
    "    plt.title(\"Binned LD +/- 1 sem\")\n",
    "    if (logscale): plt.xscale('log')\n",
    "    # plt.yscale('log')\n",
    "    plt.xlabel(\"Distance between SNPs (bp) [Left bound of distance bin]\")\n",
    "    plt.ylabel(\"Average LD in bin\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, \"correlation_vs_dist_intersectSNP.pdf\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For each dataset LD pairs were stratified by LD values in Real, cut into nbins bins\n",
    "# binnedLD contains the average LD in each bin\n",
    "# Plot generated average LD as a function of the real average LD in the bins\n",
    "plt.figure(figsize=(10, 10))\n",
    "for model_name, bld in binnedLD.items():\n",
    "    plt.errorbar(bld.bin_edges.values, bld.LD.values, bld['sem'].values, label=model_name, alpha=1, marker='o')\n",
    "plt.title(\"Binned LD +/- 1 sem\")\n",
    "plt.xlabel(\"Bins (LD in Real)\")\n",
    "plt.ylabel(\"Average LD in bin\")\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    os.path.join(output_dir, 'LD_{}bins_{}fixedremoved.pdf'.format(nbins, 'logdist_' if logscale else '')))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Set edges of the region for which to plot LD block matrix (l=0, f='end') for full region\n",
    "# # not used as for now apart from the filename\n",
    "# l_bound = None\n",
    "# r_bound = None\n",
    "# snpcode = \"fullSNP\"\n",
    "# mirror, diff = False, False\n",
    "# outfilename = f\"LD_HEATMAP_{snpcode}_bounds={l_bound}-{r_bound}_mirror={mirror}_diff={diff}.pdf\"\n",
    "# fig = plt.figure(figsize=(10 * len(hcor_snp), 10))\n",
    "# plotLDblock(hcor_snp,\n",
    "#             left=l_bound, right=r_bound,  # None, None -> takes all SNPs\n",
    "#             mirror=mirror, diff=diff,\n",
    "#             is_fixed=is_fixed, is_fixed_dic=is_fixed_dic,\n",
    "#             suptitle_kws={'t': outfilename}\n",
    "#             )\n",
    "# plt.title(outfilename)\n",
    "# plt.savefig(os.path.join(output_dir, outfilename))\n",
    "# plt.show()\n",
    "#\n",
    "# print(\n",
    "#     '****************************************************************\\n*** Computation and plotting LD DONE. Figures saved in {} ***\\n****************************************************************'.format(\n",
    "#         output_dir))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dSS_dic = dict()\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "for cat, mat in datasets.items():\n",
    "    dAB = distance.cdist(mat, mat, 'cityblock')\n",
    "    np.fill_diagonal(dAB, np.Inf)\n",
    "    dSS_dic[cat] = dAB.min(axis=1)\n",
    "    sns.kdeplot(dAB[np.triu_indices(dAB.shape[0], k=1)], linewidth=3, label=cat)  # dSS\n",
    "plt.title(\"Pairwise distance within each dataset\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for cat, d in dSS_dic.items():\n",
    "    sns.kdeplot(dSS_dic[cat], linewidth=3, label=cat)\n",
    "plt.title(\"Minimal pairwise distance within each dataset\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, \"haplo_pairw_distrib_within.pdf\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "haplo = np.concatenate(list(datasets.values())).T  # orientation of scikit allele\n",
    "\n",
    "outFilePrefix = ''\n",
    "# if not ref in model_name_to_input_file.keys(): continue\n",
    "ref = 'Real'\n",
    "print(\"Computing AATS with ref \" + ref)\n",
    "AA, MINDIST = computeAAandDist(\n",
    "    pd.DataFrame(haplo.T),\n",
    "    extra_sample_info.label,\n",
    "    model_name_to_input_file.keys(),\n",
    "    refCateg=ref,\n",
    "    saveAllDist=True,\n",
    "    output_dir=output_dir,\n",
    "    outFilePrefix=outFilePrefix)\n",
    "\n",
    "# save AA and MINDIST pd.DataFrame to csv\n",
    "# np.array of all pariwise distances are saved as npz automatically when calling computeAAandDist with saveAllDist=True\n",
    "AA.to_csv(os.path.join(output_dir, f'AA_{ref}.csv.bz2'), index=None)\n",
    "MINDIST.to_csv(os.path.join(output_dir, f'MINDIST_{ref}.csv.bz2'), index=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Distribution WITHIN model_namesories\n",
    "W = pd.DataFrame(columns=['stat', 'statistic', 'label', 'comparaison'])\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 2, 1)\n",
    "model_names = model_name_to_input_file.keys()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    subset = (np.load('{}/dist_{}_{}.npz'.format(output_dir, model_name, model_name)))['dist']\n",
    "    if model_name == 'Real':\n",
    "        subsetreal = subset\n",
    "    sns.kdeplot(subset, linewidth=3, label='{} ({} identical pairs)'.format(model_name, (subset == 0).sum()))\n",
    "\n",
    "    sc = scs.wasserstein_distance(subsetreal, subset)\n",
    "    new_row = pd.DataFrame(\n",
    "        {'stat': ['wasserstein'], 'statistic': [sc], 'label': [model_name], 'comparaison': ['within']})\n",
    "    W = pd.concat([W, new_row], ignore_index=True)\n",
    "\n",
    "plt.title(\"Distribution of haplotypic pairwise difference within each dataset\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(MINDIST)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DISTmelt = MINDIST.melt(id_vars='cat').rename(columns=str.title)\n",
    "# g = sns.FacetGrid(DISTmelt, hue=\"Cat\", height=7, col='Variable', hue_order=model_name_to_input_file.keys())\n",
    "# # cut=0 : negative values have no meaning for distances, however be aware that this might accidently hide real picks at zero (due to copying for example)\n",
    "# # check whether the full distribution is  similar or not (next cell)\n",
    "# g.map(sns.kdeplot, \"Value\")\n",
    "# g.add_legend()\n",
    "# plt.savefig(os.path.join(output_dir, \"distrib_minimal_distances_cut.pdf\"))\n",
    "#\n",
    "# DISTmelt = MINDIST.melt(id_vars='cat').rename(columns=str.title)\n",
    "# g = sns.FacetGrid(DISTmelt, hue=\"Cat\", height=7, col='Variable', hue_order=model_name_to_input_file.keys())\n",
    "# g.map(sns.kdeplot, \"Value\")\n",
    "# g.add_legend()\n",
    "# plt.savefig(os.path.join(output_dir, \"distrib_minimal_distances_full.pdf\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W = pd.DataFrame(columns=['stat', 'statistic', 'label', 'comparaison'])\n",
    "for model_name in model_name_to_input_file.keys():\n",
    "    for method in ['dTS', 'dST']:\n",
    "        real = MINDIST[method][MINDIST.cat == 'Real'][0]\n",
    "        sc = scs.wasserstein_distance(real, MINDIST[method][MINDIST.cat == model_name].values[0])\n",
    "        new_row = pd.DataFrame({'stat': ['wasserstein'], 'statistic': [sc],\n",
    "                                'label': [model_name], 'comparaison': [method]})\n",
    "        W = pd.concat([W, new_row], ignore_index=True)\n",
    "scores = pd.concat([W])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = pd.concat([scores, W])\n",
    "scores.to_csv(os.path.join(output_dir, \"scores_pairwise_distances.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(1.5 * len(model_names), 6))\n",
    "\n",
    "sns.barplot(x='Cat', y='Value', hue='Variable', palette=sns.color_palette('colorblind'),\n",
    "            data=(AA.drop(columns=['PrivacyLoss', 'ref'], errors='ignore')).melt(id_vars='cat').rename(\n",
    "                columns=str.title))\n",
    "plt.axhline(0.5, color='black')\n",
    "if 'Real_test' in AA.cat.values:\n",
    "    plt.axhline(np.float(AA[AA.cat == 'Real_test'].AATS), color=sns.color_palette()[0], ls='--')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.title(\"Nearest Neighbor Adversarial Accuracy on training (AATS) and its components\")\n",
    "plt.savefig(os.path.join(output_dir, \"AATS_scores.pdf\"))\n",
    "\n",
    "Test = '_Test2'\n",
    "Train = ''  # means Training set is Real\n",
    "dfPL = plotPrivacyLoss(Train, Test, output_dir, color_palette, model_name_to_color)\n",
    "\n",
    "# Compute PL for the real dataset Test1\n",
    "# Useful if an RBM with alternative training scheme (cf paper) is in the list of models\n",
    "# Because Test1 served for initializing the RBM sampling in this case\n",
    "Test = '_Test2'\n",
    "Train = '_Test1'\n",
    "dfPL = plotPrivacyLoss(Train, Test, output_dir, color_palette, model_name_to_color)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_counts(haplosubset, points):\n",
    "    counts = np.unique(\n",
    "        np.apply_along_axis(\n",
    "            lambda x: ''.join(map(str, x[points])),\n",
    "            # lambda x: ''.join([str(x[p]) for p in points]),\n",
    "            0, haplosubset),\n",
    "        return_counts=True)\n",
    "    return (counts)\n",
    "\n",
    "\n",
    "def get_frequencies(counts):\n",
    "    l = len(counts[0][0])  # haplotype length\n",
    "    nind = np.sum(counts[1])\n",
    "    f = np.zeros(shape=[2] * l)\n",
    "    for i, allele in enumerate(counts[0]):\n",
    "        f[tuple(map(int, allele))] = counts[1][i] / nind\n",
    "    return f\n",
    "\n",
    "\n",
    "def three_points_cor(haplosubset, out='all'):\n",
    "    F = dict()\n",
    "    for points in [[0], [1], [2], [0, 1], [0, 2], [1, 2], [0, 1, 2]]:\n",
    "        strpoints = ''.join(map(str, points))\n",
    "        F[strpoints] = get_frequencies(\n",
    "            get_counts(haplosubset, points)\n",
    "        )\n",
    "\n",
    "    cors = [\n",
    "        F['012'][a, b, c] - F['01'][a, b] * F['2'][c] - F['12'][b, c] * F['0'][a] - F['02'][a, c] * F['1'][b] + 2 *\n",
    "        F['0'][a] * F['1'][b] * F['2'][c] for a, b, c in itertools.product(*[[0, 1]] * 3)]\n",
    "    if out == 'mean':\n",
    "        return (np.mean(cors))\n",
    "    if out == 'max':\n",
    "        return (np.max(np.abs(cors)))\n",
    "    if out == 'all':\n",
    "        return (cors)\n",
    "    return (ValueError(f\"out={out} not recognized\"))\n",
    "\n",
    "\n",
    "# def mult_three_point_cor(haplo, extra_sample_info, model_name, picked_three_points):\n",
    "#    return [three_points_cor(haplo[np.ix_(snps,extra_sample_info.label==model_name)], out='all') for snps in picked_three_points]\n",
    "\n",
    "# set the seed so that the same real individual are subsampled (when needed)\n",
    "# to ensure consistency of the scores when adding a new model or a new sumstat\n",
    "np.random.seed(3)\n",
    "random.seed(3)\n",
    "\n",
    "# Compute 3 point correlations results for different datasets and different distances between SNPs\n",
    "\n",
    "# pick distance between SNPs at which 3point corr will be computed\n",
    "# (defined in nb of snps)\n",
    "# a gap of -9 means that snp triplets are chosen completely at random (not predefined distance)\n",
    "# for each category we randomly pick 'nsamplesets' triplets\n",
    "\n",
    "# if datasets have different nb of snps, for convenience we will sample\n",
    "# slightly more at the beginning of the chunk\n",
    "\n",
    "gap_vec = [1, 4, 16, 64, 256, 512, 1024, -9]\n",
    "nsamplesets = 1000\n",
    "min_nsnp = min([dat.shape[1] for dat in datasets.values()])\n",
    "cors_meta = dict()\n",
    "for gap in gap_vec:\n",
    "    print(f'\\n gap={gap} SNPs', end=' ')\n",
    "    if gap < 0:\n",
    "        # pick 3 random snps\n",
    "        picked_three_points = [random.sample(range(min_nsnp), 3) for _ in range(nsamplesets)]\n",
    "    else:\n",
    "        try:\n",
    "            # pick 3 successive snps spearated by 'gap' SNPs\n",
    "            step = gap + 1\n",
    "            picked_three_points = [np.asarray(random.sample(range(min_nsnp - 2 * step), 1)) + [0, step, 2 * step]\n",
    "                                   for _\n",
    "                                   in range(nsamplesets)]\n",
    "        except:\n",
    "            continue  # if there were not enough SNPs for this gap\n",
    "    cors = dict()\n",
    "\n",
    "    for model_name in model_name_to_input_file.keys():\n",
    "        print(model_name, end=' ')\n",
    "        # cors[model_name]=[three_points_cor(haplo[np.ix_(snps,extra_sample_info.label==model_name)], out='all') for snps in picked_three_points]\n",
    "        cors[model_name] = [three_points_cor(datasets[model_name][:, snps].T, out='all') for snps in\n",
    "                            picked_three_points]\n",
    "\n",
    "    cors_meta[gap] = cors.copy()\n",
    "\n",
    "# print(cors_meta)\n",
    "\n",
    "with open(os.path.join(output_dir, \"3pointcorr.pkl\"), \"wb\") as outfile:\n",
    "    pickle.dump(cors_meta, outfile)\n",
    "\n",
    "# Plot 3-point correlations results\n",
    "\n",
    "plt.figure(figsize=(2 * len(cors_meta), 7))\n",
    "# plt.figure(figsize=(figwi,figwi/2))\n",
    "for i, gap in enumerate((cors_meta).keys()):\n",
    "    ax = plt.subplot(2, int(np.ceil(len(cors_meta) / 2)), int(i) + 1)\n",
    "    cors = cors_meta[gap]\n",
    "    real = list(np.array(cors['Real']).flat)\n",
    "    lims = [np.min(real), np.max(real)]\n",
    "    for key, val in cors.items():\n",
    "        if key == 'Real': continue\n",
    "        val = list(np.array(val).flat)\n",
    "        plotreg(x=real, y=val, keys=['Real', key],\n",
    "                statname='Correlation', col=color_palette[key], ax=ax)\n",
    "    if gap < 0:\n",
    "        plt.title('3-point corr for random SNPs')\n",
    "    else:\n",
    "        plt.title(f'3-point corr for SNPs sep. by {gap} SNPs')\n",
    "\n",
    "    plt.legend(fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, '3point_correlations.jpg'), dpi=300)  # can pick one of the format\n",
    "\n",
    "# Same plot with axes limit fixed to (-0.1,0.1) for the sake of comparison\n",
    "\n",
    "plt.figure(figsize=(4 * len(cors_meta), 14))\n",
    "# plt.figure(figsize=(figwi,figwi/2))\n",
    "for i, gap in enumerate((cors_meta).keys()):\n",
    "    ax = plt.subplot(2, int(np.ceil(len(cors_meta) / 2)), int(i) + 1)\n",
    "    cors = cors_meta[gap]\n",
    "    real = list(np.array(cors['Real']).flat)\n",
    "    lims = [np.min(real), np.max(real)]\n",
    "    for key, val in cors.items():\n",
    "        if key == 'Real': continue\n",
    "        val = list(np.array(val).flat)\n",
    "        plotreg(x=real, y=val, keys=['Real', key],\n",
    "                statname='Correlation', col=color_palette[key], ax=ax)\n",
    "        ax.set_xlim((-.1, .1))\n",
    "        ax.set_ylim((-.1, .1))\n",
    "\n",
    "    if gap < 0:\n",
    "        plt.title('3-point corr for random SNPs')\n",
    "    else:\n",
    "        plt.title(f'3-point corr for SNPs sep. by {gap} SNPs')\n",
    "\n",
    "    plt.legend(fontsize='small')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, '3point_correlations_fixlim.pdf'), dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
