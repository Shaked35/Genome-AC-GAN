{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.stats import sem\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from utils.util import *\n",
    "%matplotlib inline\n",
    "try:\n",
    "    import ot\n",
    "\n",
    "    ot_loaded = True\n",
    "except ModuleNotFoundError:\n",
    "    ot_loaded = False\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    sm_loaded = True\n",
    "except ModuleNotFoundError:\n",
    "    sm_loaded = False\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialize Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_to_data = {\n",
    "    \"Real\": {\n",
    "        \"path\": \"resource/test_0.2_super_pop.csv\",\n",
    "        \"color\": \"black\",\n",
    "        \"type\": \"dataset\"\n",
    "    },\n",
    "    \"Train Set\": {\n",
    "        \"path\": \"resource/train_0.8_super_pop.csv\",\n",
    "        \"color\": \"gray\",\n",
    "        \"type\": \"dataset\"\n",
    "    },\n",
    "    \"GAN19\": {\n",
    "        \"path\": \"fake_genotypes_sequences/preview_sequences/old GAN retrain genotypes.hapt\",\n",
    "        \"color\": \"red\",\n",
    "        \"type\": \"retrain_old_model\"\n",
    "    },\n",
    "    \"RBM23\": {\n",
    "        \"path\": \"fake_genotypes_sequences/preview_sequences/10K_SNP_GAN_AG_10800Epochs.hapt\",\n",
    "        \"color\": \"orange\"\n",
    "    },\n",
    "    \"WGAN23\": {\n",
    "        \"path\": \"fake_genotypes_sequences/preview_sequences/10K_WGAN.hapt\",\n",
    "        \"color\": \"pink\"\n",
    "    },\n",
    "    \"AC-GAN-Nat\": {\n",
    "        \"path\": \"resource/Genome-AC-GAN By National Population genotypes.hapt\",\n",
    "        \"color\": \"green\",\n",
    "        \"type\": \"new_model\"\n",
    "    },\n",
    "    \"AC-GAN-Con\": {\n",
    "        \"path\": \"resource/Genome-AC-GAN By Continental Population genotypes.hapt\",\n",
    "        \"color\": \"blue\",\n",
    "        \"type\": \"new_model\"\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_dir = os.environ.get(\"output_dir\", DEFAULT_EXPERIMENT_OUTPUT_DIR)\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "compute_AATS = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "color_palette = {model_name: values[\"color\"] for (model_name, values) in models_to_data.items()}\n",
    "sns.set_palette(color_palette.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_analysis_data_agg_tests(models_to_data: dict, number_of_datasets: int):\n",
    "    transformations = {'to_minor_encoding': False, 'min_af': 0, 'max_af': 1}\n",
    "\n",
    "    model_keep_all_snps, sample_info = dict(), dict()\n",
    "    # initialize real data\n",
    "    real_data = models_to_data['Real']\n",
    "    model_sequences_df = pd.read_csv(f\"../{real_data['path']}\")\n",
    "    test_dataset = prepare_test_and_fake_dataset(\"../resource\", test_path=f\"../{real_data['path']}\",\n",
    "                                                 target_column=\"Population code\")\n",
    "    columns = get_relevant_columns(model_sequences_df, [\"Population code\", \"Superpopulation code\"])\n",
    "    real_sequences = model_sequences_df[columns]\n",
    "    columns = [int(i) for i in range(len(columns) - 2)] + [\"Population code\", \"Superpopulation code\"]\n",
    "    real_sequences.columns = columns\n",
    "    real_sequences = real_sequences.sample(frac=1).reset_index(drop=True)\n",
    "    number_of_samples = len(real_sequences)\n",
    "    datasets = {'Real': [np.array(real_sequences.iloc[:, :-2].astype(int))]}\n",
    "    full_datasets = {'Real': np.array(real_sequences.iloc[:, :-2].astype(int))}\n",
    "    print('Real: ', datasets['Real'][0].shape)\n",
    "    # init all other datasets\n",
    "    for model_name, data in models_to_data.items():\n",
    "        if model_name != 'Real':\n",
    "            print(f\"init data from {model_name} with type {data.get('type', 'none')}\")\n",
    "            file_path = f\"../{data['path']}\"\n",
    "            datasets[model_name], full_datasets[model_name] = load_random_datasets(data, file_path, number_of_samples,\n",
    "                                                                                   number_of_datasets)\n",
    "\n",
    "    extra_sample_info = None\n",
    "    print(\"Dictionary of datasets:\", len(datasets))\n",
    "    return extra_sample_info, sample_info, datasets, transformations, model_keep_all_snps, number_of_samples, full_datasets, test_dataset\n",
    "\n",
    "\n",
    "def load_random_datasets(data, file_path, number_of_samples, number_of_datasets):\n",
    "    if data.get(\"type\", \"\") == \"dataset\":\n",
    "        model_sequences = pd.read_csv(file_path)\n",
    "        columns = get_relevant_columns(model_sequences, [\"Population code\", \"Superpopulation code\"])\n",
    "        model_sequences = model_sequences[columns]\n",
    "        columns = [int(i) for i in range(len(columns) - 2)] + [\"Population\", \"Superpopulation code\"]\n",
    "        model_sequences.columns = columns\n",
    "        model_sequences = model_sequences.sample(frac=1).reset_index(drop=True)\n",
    "        full_dataset = model_sequences.iloc[:, :-2]\n",
    "    else:\n",
    "        model_sequences = pd.read_csv(file_path, sep=' ', header=None)\n",
    "        model_sequences.columns = [\"Population\" if column == 0 else column - 1 for column in model_sequences.columns]\n",
    "        if 10000 in list(model_sequences.columns):\n",
    "            model_sequences = model_sequences.drop(0, axis=1)\n",
    "            model_sequences.columns = [column if column == \"Population\" else column - 1 for column in\n",
    "                                       model_sequences.columns]\n",
    "        model_sequences[\"Population\"] = model_sequences[\"Population\"].str.replace('Fake_', \"\")\n",
    "\n",
    "        full_dataset = model_sequences.iloc[:, 1:]\n",
    "\n",
    "    category_counts = model_sequences[\"Population\"].value_counts()\n",
    "    sample_counts = (\n",
    "                category_counts / category_counts.sum() * min(number_of_samples + 50, len(model_sequences))).astype(int)\n",
    "    print(f\"Total number of samples in this model are: {len(model_sequences)}\")\n",
    "    datasets = []\n",
    "    for _ in range(number_of_datasets):\n",
    "        tmp_model_sequences = model_sequences.sample(frac=1).reset_index(drop=True)\n",
    "        # Sample rows from each category\n",
    "        tmp_model_sequences = tmp_model_sequences.groupby(\"Population\").apply(\n",
    "            lambda x: x.sample(sample_counts[x.name])).reset_index(drop=True)\n",
    "        if len(tmp_model_sequences) > number_of_samples:\n",
    "            # Generate random indices to drop\n",
    "            random_indices = np.random.choice(tmp_model_sequences.index, len(tmp_model_sequences) - number_of_samples,\n",
    "                                              replace=False)\n",
    "\n",
    "            # Drop the rows corresponding to the random indices\n",
    "            tmp_model_sequences = tmp_model_sequences.drop(random_indices)\n",
    "\n",
    "            # Reset the index if needed\n",
    "            tmp_model_sequences.reset_index(drop=True, inplace=True)\n",
    "        if data.get(\"type\", \"\") != \"dataset\":\n",
    "            tmp_model_sequences = tmp_model_sequences.iloc[:, 1:]\n",
    "        else:\n",
    "            tmp_model_sequences = tmp_model_sequences.iloc[:, :-2]\n",
    "        datasets.append(tmp_model_sequences)\n",
    "    return datasets, full_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extra_sample_info, sample_info, multiple_datasets, transformations, model_keep_all_snps, number_of_samples, full_datasets, test_dataset = load_analysis_data_agg_tests(\n",
    "    models_to_data, 50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def plot_pca_comparison(models):\n",
    "    model_to_wasserstein_dists = {}\n",
    "    all_best_sequences = {}\n",
    "    # Extract the 'Real' model data\n",
    "    real_model = models['Real'][0]\n",
    "    all_best_sequences['Real'] = real_model\n",
    "    # Perform PCA on the 'Real' model\n",
    "    # tsne = TSNE(n_components=2, init='pca', learning_rate='auto', random_state=42)  # Adjust parameters as needed\n",
    "    # pca_real_transformed = tsne.fit_transform(real_model)\n",
    "\n",
    "    pca_real = PCA(n_components=2)\n",
    "    pca_real.fit(real_model)\n",
    "    pca_real_transformed = pca_real.transform(real_model)\n",
    "\n",
    "    # Plotting parameters\n",
    "    num_models = len(models) - 1\n",
    "    num_rows = int(np.ceil(num_models / 3))\n",
    "    num_cols = min(num_models, 3)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
    "\n",
    "    for i, (model_name, model_sequences) in enumerate(models.items()):\n",
    "        # Skip 'Real' model\n",
    "        if model_name == 'Real':\n",
    "            continue\n",
    "\n",
    "        print(f\"start model: {model_name} get best sequences\")\n",
    "        all_wasserstein_dist, best_model_sequence, best_pca_transformed = \\\n",
    "            get_best_pca_wasserstein(model_sequences, pca_real_transformed)\n",
    "        mean_all_wasserstein_dist = np.mean(all_wasserstein_dist)\n",
    "        std_all_wasserstein_dist = np.std(all_wasserstein_dist)\n",
    "        min_all_wasserstein_dist = np.min(all_wasserstein_dist)\n",
    "        model_to_wasserstein_dists[model_name] = all_wasserstein_dist\n",
    "        all_best_sequences[model_name] = best_model_sequence\n",
    "        print(\n",
    "            f\"finished model: {model_name} get best sequences with mean: {mean_all_wasserstein_dist}, std: {std_all_wasserstein_dist}, min: {min_all_wasserstein_dist}\")\n",
    "        # Set subplot position\n",
    "        position = i - 1\n",
    "        row = position // num_cols\n",
    "        col = position % num_cols\n",
    "\n",
    "        # Plot PCA comparison\n",
    "        ax = axes[row, col]\n",
    "        ax.scatter(pca_real_transformed[:, 0], pca_real_transformed[:, 1], color=color_palette['Real'], alpha=0.8)\n",
    "        ax.scatter(best_pca_transformed[:, 0], best_pca_transformed[:, 1], color=color_palette[model_name], alpha=0.6)\n",
    "        title = \"\\n\".join(model_name.split(\"By\"))\n",
    "        ax.set_title(title, fontsize=25, fontweight='bold')\n",
    "\n",
    "    # Adjust the spacing between the first row and the second column\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    plt.savefig(os.path.join(output_dir, \"pca2_on_test_real.jpg\"), bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    return model_to_wasserstein_dists, all_best_sequences\n",
    "\n",
    "\n",
    "def get_best_pca_wasserstein(model_sequences, pca_real_transformed):\n",
    "    all_wasserstein_dist = []\n",
    "    best_wasserstein_dist = np.inf\n",
    "    best_model_sequence = None\n",
    "    best_pca_transformed = None\n",
    "    for model_sequence in model_sequences:\n",
    "        # Perform PCA on the current model\n",
    "        pca_model = PCA(n_components=2)\n",
    "        pca_model.fit(model_sequence)\n",
    "        pca_model_transformed = pca_model.transform(model_sequence)\n",
    "        # Calculate the Wasserstein distance\n",
    "        tmp_wasserstein_dist = calculate_2d_wasserstein_distance(pca_real_transformed, pca_model_transformed)\n",
    "        all_wasserstein_dist.append(tmp_wasserstein_dist)\n",
    "        if tmp_wasserstein_dist < best_wasserstein_dist:\n",
    "            best_wasserstein_dist = tmp_wasserstein_dist\n",
    "            best_model_sequence = model_sequence\n",
    "            best_pca_transformed = pca_model_transformed\n",
    "    return all_wasserstein_dist, best_model_sequence, best_pca_transformed\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_to_wasserstein_dists, all_best_sequences = plot_pca_comparison(multiple_datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_names = list(model_to_wasserstein_dists.keys())\n",
    "model_names = [\"\\n\".join(model_name.split(\"By\")) for model_name in model_names]\n",
    "model_names = [\"\\n\".join(model_name.split(\"Model\")) for model_name in model_names]\n",
    "wasserstein_distances = list(model_to_wasserstein_dists.values())\n",
    "\n",
    "p_values = []\n",
    "for i in range(len(model_names)):\n",
    "    for j in range(i + 1, len(model_names)):\n",
    "        p_values.append(1 - stats.ttest_ind(wasserstein_distances[i], wasserstein_distances[j]).pvalue)\n",
    "\n",
    "# Reshape the p_values into a 2D matrix\n",
    "n = len(model_names)\n",
    "p_values_matrix = np.zeros((n, n))\n",
    "p_values_matrix[np.triu_indices(n, 1)] = p_values\n",
    "p_values_matrix += p_values_matrix.T\n",
    "\n",
    "# Create a plot matrix of the p-values\n",
    "fig, ax = plt.subplots(figsize=(15, 15))  # Increase the size of the plot\n",
    "im = ax.imshow(p_values_matrix, cmap='coolwarm', vmin=0, vmax=1)\n",
    "ax.set_xticks(np.arange(len(model_names)))\n",
    "ax.set_yticks(np.arange(len(model_names)))\n",
    "ax.set_xticklabels(model_names, rotation=45)\n",
    "ax.set_yticklabels(model_names)\n",
    "\n",
    "# Add numerical values in the matrix\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        text = ax.text(j, i, f'{p_values_matrix[i, j] * 100:.5f}%', ha='center', va='center', color='w', fontsize=15)\n",
    "\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, \"P-values wasserstein_distances\"))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.std(model_to_wasserstein_dists['WGAN23'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wasserstein Distance Plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a dictionary called `wasserstein_dict` with model names as keys and Wasserstein Distance lists as values\n",
    "# and a dictionary called `color_palette` with model names as keys and color names as values\n",
    "\n",
    "# Calculate the mean and standard deviation for each model's Wasserstein Distance list\n",
    "means = {}\n",
    "stds = {}\n",
    "boxprops = dict(linewidth=3, color='black')\n",
    "medianprops = dict(linewidth=3, color='black')\n",
    "meanprops = dict(marker='o', markeredgecolor='blue', markersize=10)\n",
    "\n",
    "for model, distances in model_to_wasserstein_dists.items():\n",
    "    model_display_name = \"\\n\".join(model.split(\"By\"))\n",
    "    model_display_name = \"\\n\".join(model_display_name.split(\"Model\"))\n",
    "    means[model_display_name] = np.mean(distances)\n",
    "    stds[model_display_name] = np.std(distances)\n",
    "\n",
    "# Sort the model names alphabetically\n",
    "sorted_models = list(model_to_wasserstein_dists.keys())\n",
    "\n",
    "# Get the colors from the color palette based on the sorted model names\n",
    "colors = [color_palette[model] for model in sorted_models]\n",
    "\n",
    "# Plotting the mean and standard deviation for each model\n",
    "data = [model_to_wasserstein_dists[model] for model in sorted_models]\n",
    "sorted_models = [\"\\n\".join(model_name.split(\"By\")) for model_name in sorted_models]\n",
    "sorted_models = [\"\\n\".join(model_name.split(\"Model\")) for model_name in sorted_models]\n",
    "# Plotting the boxplot for each model\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "boxplot = ax.boxplot(data, labels=sorted_models, patch_artist=True, showfliers=False, boxprops=boxprops,\n",
    "                     medianprops=medianprops, meanprops=meanprops,\n",
    "                     whiskerprops=dict(linestyle='dotted', linewidth=5.0, color='black'))\n",
    "\n",
    "# Set the colors for the boxes based on the color palette\n",
    "for patch_artist, color in zip(boxplot['boxes'], colors):\n",
    "    patch_artist.set_facecolor(color)\n",
    "\n",
    "# Add text annotations for mean and standard deviation values in the label\n",
    "for i, model in enumerate(sorted_models):\n",
    "    mean = means[model]\n",
    "    std = stds[model]\n",
    "    label = f\"Mean: {mean:.2f}\\nStd: {std:.2f}\"\n",
    "    pos = 400 if i != 1 else -250 if i == 1 else -150\n",
    "    print(mean + std + pos)\n",
    "    ax.text(i + 1, mean + std + pos, label, ha='center', va='top', fontsize=24, color='white', fontweight='bold',\n",
    "            bbox=dict(facecolor='black', edgecolor='black', boxstyle='round', pad=0.1))\n",
    "\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_weight('bold')\n",
    "    label.set_size(16)\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_weight('bold')\n",
    "    label.set_size(16)\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Wasserstein Distance', fontweight='bold', fontsize=17)\n",
    "\n",
    "ax.grid(True, color='black')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(os.path.join(output_dir, \"Wasserstein Distance Comparison.jpg\"), bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MAF Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum_alleles_by_position, allele_frequency, is_fixed = build_allele_frequency(full_datasets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "def plotreg(x, y, keys, statname, col, model_name_display, ax=None):\n",
    "    \"\"\"\n",
    "    Plot for x versus y with regression scores and returns correlation coefficient and MSE\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like, scalar\n",
    "    y : array-like, scalar\n",
    "    keys : tuple\n",
    "        Tuple containing the model names or keys\n",
    "    statname : str\n",
    "        'Allele frequency', 'LD', or '3 point correlation', etc.\n",
    "    col : str\n",
    "        Color code or name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r : float\n",
    "        Pearson correlation coefficient between x and y\n",
    "    mse : float\n",
    "        Mean Squared Error between x and y\n",
    "    \"\"\"\n",
    "\n",
    "    lims = [np.min(x), np.max(x)]\n",
    "    r, _ = pearsonr(x, y)\n",
    "    mae = mean_absolute_error(x, y)\n",
    "\n",
    "    if sm_loaded:\n",
    "        reg = sm.OLS(x, y).fit()\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "    if len(x) < 100:\n",
    "        alpha = 1\n",
    "    else:\n",
    "        alpha = .6\n",
    "\n",
    "    ax.plot(x, y, c=col, marker='o', lw=0, alpha=alpha)\n",
    "    ax.plot(lims, lims, ls='--', alpha=1, c='black')\n",
    "    title = ax.set_title(\n",
    "        f'{model_name_display}\\nCorrelation={round(r * 100, 2)}%\\nMAE={round(mae, 4)}',\n",
    "        fontsize=29, fontweight=\"bold\", y=1, color='black')\n",
    "\n",
    "    title.set_bbox({'facecolor': 'white', 'edgecolor': \"black\", 'pad': 1.2})\n",
    "    ax.set_xlabel(\"MAF In Real\", fontsize=28, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"MAF In Synthetic\", fontsize=28, fontweight=\"bold\")\n",
    "\n",
    "    ax.plot(x, y, c=col, marker='o', lw=0)\n",
    "    ax.plot(lims, lims, ls='--', alpha=1, c='black')\n",
    "    title = ax.set_title(\n",
    "        f'{model_name_display}\\nCorrelation={round(r * 100, 2)}%\\nMAE={round(mae, 4)}',\n",
    "        fontsize=35, fontweight=\"bold\", y=1, color='black')\n",
    "    title.set_bbox({'facecolor': (0.9, 0.9, 0.9), 'edgecolor': \"black\", 'pad': 1.5})\n",
    "    ax.set_xlabel(\"MAF In Real\", fontsize=25, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"MAF In Synthetic\", fontsize=25, fontweight=\"bold\")\n",
    "    # Adjust vertical spacing between subplots\n",
    "    # plt.subplots_adjust(hspace=0.2, wspace=0.5)\n",
    "\n",
    "    return r, mae\n",
    "\n",
    "\n",
    "def plotregquant(x, y, keys, statname, col, model_name_display, step=0.05, cumsum=False, ax=None):\n",
    "    \"\"\"\n",
    "    Plot quantiles for x versus y (every step) with regression scores and returns correlation coefficient\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array, scalar\n",
    "    y : array, scalar\n",
    "    statname : str\n",
    "        'Allele frequency' LD' or '3 point correlation' etc.\n",
    "    col : str, color code\n",
    "        color\n",
    "    step : float\n",
    "        step between quantiles\n",
    "    cumsum : boolean\n",
    "        plot cumulative sum of quantiles instead\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    r: float\n",
    "        Pearson correlation coefficient\n",
    "\n",
    "    \"\"\"\n",
    "    q = np.arange(0, 1, step=step)\n",
    "    x = np.nanquantile(x, q)\n",
    "    y = np.nanquantile(y, q)\n",
    "    if cumsum:\n",
    "        x = np.cumsum(x)\n",
    "        y = np.cumsum(y)\n",
    "    r = plotreg(x=x, y=y, keys=keys, statname=f'Quantiles {statname}', col=col, ax=ax,\n",
    "                model_name_display=model_name_display)\n",
    "    return r\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_allele_frequency(allele_frequency, file_name, maf, highest=False):\n",
    "    # Plotting Allele frequencies in Generated vs Real\n",
    "    # below a certain real frequency\n",
    "    figwi = 14\n",
    "    l, c = 1, 6\n",
    "    plt.figure(figsize=(44, 6))\n",
    "    if highest:\n",
    "        maf = 1 - maf\n",
    "        keep = (allele_frequency['Real'] >= maf)\n",
    "    else:\n",
    "        keep = (allele_frequency['Real'] <= maf)\n",
    "    for i, (model_name, val) in enumerate(allele_frequency.items()):\n",
    "        model_name_display = model_name.replace(\"Population\", \"\").replace(\" By\", \"\").replace(\"Genome-AC-GAN\",\n",
    "                                                                                             \"Genome-AC-GAN\\n\")\n",
    "        if model_name != 'Real':\n",
    "            ax = plt.subplot(int(l), c, i)\n",
    "            plotreg(x=allele_frequency['Real'][keep], y=val[keep],\n",
    "                    keys=['Real', model_name_display], statname=\"Allele frequency\",\n",
    "                    col=color_palette[model_name], model_name_display=model_name_display, ax=ax)\n",
    "\n",
    "    plt.savefig(os.path.join(output_dir, file_name), bbox_inches='tight', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_allele_frequency(allele_frequency, 'total_allele_frequency.jpg', 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_allele_frequency(allele_frequency, 'zoom_lowest_total_allele_frequency.jpg', 0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_allele_frequency(allele_frequency, 'zoom_highest_total_allele_frequency.jpg', 0.2, highest=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LD Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"* Computing and plotting LD...\")\n",
    "#### Compute correlation between all pairs of SNPs for each generated/real dataset\n",
    "\n",
    "model_names = models_to_data.keys()\n",
    "hcor_snp = dict()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    print(model_name)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Catch warnings due to fixed sites in dataset (the correlation value will be np.nan for pairs involving these sites)\n",
    "        hcor_snp[model_name] = np.corrcoef(full_datasets[model_name], rowvar=False) ** 2  # r2\n",
    "\n",
    "_, region_len, snps_on_same_chrom = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", region_len_only=True,\n",
    "                                             kept_preprocessing=\"all\")\n",
    "\n",
    "nbins = 100\n",
    "logscale = True\n",
    "bins = nbins\n",
    "binsPerDist = nbins\n",
    "if logscale: binsPerDist = np.logspace(np.log(1), np.log(region_len), nbins)\n",
    "\n",
    "# Compute LD binned by distance\n",
    "# Take only sites that are SNPs in all datasets (intersect)\n",
    "# (eg intersection of SNPs in Real, SNPs in GAN, SNPs in RBM etc)\n",
    "# -> Makes sense only if there is a correspondence between sites\n",
    "\n",
    "binnedLD = dict()\n",
    "binnedPerDistLD = dict()\n",
    "kept_snp = ~is_fixed\n",
    "n_kept_snp = np.sum(kept_snp)\n",
    "realdist = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", kept_preprocessing=\"all\",\n",
    "                    kept_snp=kept_snp)[0]\n",
    "mat = hcor_snp['Real']\n",
    "# filter and flatten\n",
    "flatreal = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "isnanReal = np.isnan(flatreal)\n",
    "i = 1\n",
    "plt.figure(figsize=(10, len(hcor_snp) * 5))\n",
    "\n",
    "for model_name, mat in hcor_snp.items():\n",
    "    flathcor = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "    isnan = np.isnan(flathcor)\n",
    "    curr_dist = realdist\n",
    "\n",
    "    # For each dataset LD pairs are stratified by SNP distance and cut into 'nbins' bins\n",
    "    # bin per SNP distance\n",
    "    ld = binned_statistic(curr_dist[~isnan], flathcor[~isnan], statistic='mean', bins=binsPerDist)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)  # so that empty bins do not raise a warning\n",
    "        binnedPerDistLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                                    'LD': ld.statistic,\n",
    "                                                    # 'sd': binned_statistic(curr_dist[~isnan], flathcor[~isnan], statistic = 'std', bins=binsPerDist).statistic,\n",
    "                                                    'sem': binned_statistic(curr_dist[~isnan], flathcor[~isnan],\n",
    "                                                                            statistic=sem,\n",
    "                                                                            bins=binsPerDist).statistic,\n",
    "                                                    'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "    # For each dataset LD pairs are stratified by LD values in Real and cut into 'nbins' bins\n",
    "    # binnedLD contains the average, std of LD values in each bin\n",
    "    isnan = np.isnan(flathcor) | np.isnan(flatreal)\n",
    "    ld = binned_statistic(flatreal[~isnan], flathcor[~isnan], statistic='mean', bins=bins)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)  # so that empty bins do not raise a warning\n",
    "        binnedLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                             'LD': ld.statistic,\n",
    "                                             'sd': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                    statistic='std',\n",
    "                                                                    bins=bins).statistic,\n",
    "                                             'sem': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                     statistic=sem,\n",
    "                                                                     bins=bins).statistic,\n",
    "                                             'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "    # Plotting quantiles ?\n",
    "    plotregquant(x=flatreal, y=flathcor,\n",
    "                 keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "                 step=0.05,\n",
    "                 ax=plt.subplot(len(hcor_snp), 2, i), model_name_display=model_name)\n",
    "    i += 1\n",
    "    plt.title(f'Quantiles LD {model_name} vs Real')\n",
    "\n",
    "    # removing nan values and subsampling before doing the regression to have a reasonnable number of points\n",
    "    isnanInter = isnanReal | isnan\n",
    "    keepforplotreg = random.sample(list(np.where(~isnanInter)[0]), number_of_samples)\n",
    "    plotreg(x=flatreal[keepforplotreg], y=flathcor[keepforplotreg],\n",
    "            keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "            ax=plt.subplot(len(hcor_snp), 2, i), model_name_display=model_name)\n",
    "    i += 1\n",
    "    plt.title(f'LD {model_name} vs Real')\n",
    "plt.savefig(os.path.join(output_dir, \"LD_generated_vs_real_intersectSNP.pdf\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import binned_statistic, sem\n",
    "import warnings\n",
    "\n",
    "\n",
    "def compute_and_plot_ld(real_data, synthetic_data, output_dir):\n",
    "    model_names = synthetic_data.keys()\n",
    "    hcor_snp = dict()\n",
    "\n",
    "    for model_name in model_names:\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            hcor_snp[model_name] = np.corrcoef(real_data[model_name], rowvar=False) ** 2  # r2\n",
    "\n",
    "    _, region_len, snps_on_same_chrom = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", region_len_only=True,\n",
    "                                                 kept_preprocessing=real_data)\n",
    "\n",
    "    nbins = 100\n",
    "    logscale = True\n",
    "    bins = nbins\n",
    "    binsPerDist = nbins\n",
    "    if logscale:\n",
    "        binsPerDist = np.logspace(np.log(1), np.log(region_len), nbins)\n",
    "\n",
    "    binnedLD = dict()\n",
    "    binnedPerDistLD = dict()\n",
    "    realdist = get_dist(f\"../{REAL_POSITION_FILE_NAME}\", kept_preprocessing=real_data,\n",
    "                        kept_snp='all')[0]\n",
    "    mat = hcor_snp['Real']\n",
    "    flatreal = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "    isnanReal = np.isnan(flatreal)\n",
    "    i = 1\n",
    "\n",
    "    plt.figure(figsize=(10, len(hcor_snp) * 5))\n",
    "\n",
    "    for model_name, mat in hcor_snp.items():\n",
    "        flathcor = (mat[np.ix_(kept_snp, kept_snp)])[np.triu_indices(n_kept_snp)]\n",
    "        isnan = np.isnan(flathcor)\n",
    "        curr_dist = realdist\n",
    "\n",
    "        ld = binned_statistic(curr_dist[~isnan], flathcor[~isnan], statistic='mean', bins=binsPerDist)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            binnedPerDistLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                                        'LD': ld.statistic,\n",
    "                                                        'sem': binned_statistic(curr_dist[~isnan], flathcor[~isnan],\n",
    "                                                                                statistic=sem,\n",
    "                                                                                bins=binsPerDist).statistic,\n",
    "                                                        'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "        isnan = np.isnan(flathcor) | np.isnan(flatreal)\n",
    "        ld = binned_statistic(flatreal[~isnan], flathcor[~isnan], statistic='mean', bins=bins)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            binnedLD[model_name] = pd.DataFrame({'bin_edges': ld.bin_edges[:-1],\n",
    "                                                 'LD': ld.statistic,\n",
    "                                                 'sd': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                        statistic='std',\n",
    "                                                                        bins=bins).statistic,\n",
    "                                                 'sem': binned_statistic(flatreal[~isnan], flathcor[~isnan],\n",
    "                                                                         statistic=sem,\n",
    "                                                                         bins=bins).statistic,\n",
    "                                                 'model_name': model_name, 'logscale': logscale})\n",
    "\n",
    "        # Plotting quantiles ?\n",
    "        plotregquant(x=flatreal, y=flathcor,\n",
    "                     keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "                     step=0.05,\n",
    "                     ax=plt.subplot(len(hcor_snp), 2, i), model_name_display=model_name)\n",
    "        i += 1\n",
    "        plt.title(f'Quantiles LD {model_name} vs Real')\n",
    "\n",
    "        # removing nan values and subsampling before doing the regression to have a reasonnable number of points\n",
    "        isnanInter = isnanReal | isnan\n",
    "        keepforplotreg = random.sample(list(np.where(~isnanInter)[0]), number_of_samples)\n",
    "        plotreg(x=flatreal[keepforplotreg], y=flathcor[keepforplotreg],\n",
    "                keys=['Real', model_name], statname='LD', col=color_palette[model_name],\n",
    "                ax=plt.subplot(len(hcor_snp), 2, i), model_name_display=model_name)\n",
    "        i += 1\n",
    "        plt.title(f'LD {model_name} vs Real')\n",
    "    plt.savefig(os.path.join(output_dir, \"LD_generated_vs_real_intersectSNP.pdf\"))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AATS Privacy Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "line_styles = ['solid', 'dashdot', 'dotted']\n",
    "scores = []\n",
    "real_bld = binnedPerDistLD['Real'].LD.values[~np.isnan(binnedPerDistLD['Real'].LD.values)]\n",
    "# Calculate the absolute difference from the \"Real\" line\n",
    "for index, (model_name, bld) in enumerate(binnedPerDistLD.items()):\n",
    "    style_index = index % len(line_styles)\n",
    "    line_style = line_styles[style_index]\n",
    "    r2 = round(r2_score(real_bld, bld.LD.values[~np.isnan(bld.LD.values)]), 3)\n",
    "    rmse = round(np.sqrt(mean_squared_error(real_bld, bld.LD.values[~np.isnan(bld.LD.values)])), 3)\n",
    "    plt.errorbar(\n",
    "        bld.bin_edges.values, bld.LD.values, bld['sem'].values,\n",
    "        label=r\"$\\mathbf{\" + model_name + \"}$  RMSE = \" + str(rmse) + \", R-squared = \" + str(r2),\n",
    "        alpha=0.8, linewidth=3, linestyle=line_style\n",
    "    )\n",
    "\n",
    "# plt.title(\"Binned LD +/- 1 sem\")\n",
    "if logscale:\n",
    "    plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel(\"Distance between SNPs (bp) [Left bound of distance bin]\", fontsize=15)\n",
    "plt.ylabel(\"Average LD in bin\", fontsize=15)\n",
    "plt.legend(fontsize='x-large', loc=\"upper right\")\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, \"correlation_vs_dist_intersectSNP.jpg\"), bbox_inches='tight', dpi=500)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axes object\n",
    "fig, axes = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the data for each model\n",
    "for model_name, bld in binnedPerDistLD.items():\n",
    "    plt.errorbar(bld.bin_edges.values, bld.LD.values, bld['sem'].values, label=model_name, alpha=.65,\n",
    "                 linewidth=3, color=color_palette[model_name])\n",
    "\n",
    "# Add a title to the plot\n",
    "plt.title(\"Binned LD +/- 1 sem\")\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel(\"Distance between SNPs (bp) [Left bound of distance bin]\")\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel(\"Average LD in bin\")\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(output_dir, \"correlation_vs_dist_intersectSNP.pdf\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For each dataset LD pairs were stratified by LD values in Real, cut into nbins bins\n",
    "# binnedLD contains the average LD in each bin\n",
    "# Plot generated average LD as a function of the real average LD in the bins\n",
    "plt.figure(figsize=(10, 10))\n",
    "for model_name, bld in binnedLD.items():\n",
    "    plt.errorbar(bld.bin_edges.values, bld.LD.values, bld['sem'].values, label=model_name, alpha=0.8, marker='o')\n",
    "plt.title(\"Binned LD +/- 1 sem\")\n",
    "plt.xlabel(\"Bins (LD in Real)\")\n",
    "plt.ylabel(\"Average LD in bin\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, 'LD decay.jpg'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dSS_dic = dict()\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "for cat, mat in full_datasets.items():\n",
    "    dAB = distance.cdist(mat, mat, 'cityblock')\n",
    "    np.fill_diagonal(dAB, np.Inf)\n",
    "    dSS_dic[cat] = dAB.min(axis=1)\n",
    "    sns.kdeplot(dAB[np.triu_indices(dAB.shape[0], k=1)], linewidth=3, label=cat)  # dSS\n",
    "plt.title(\"Pairwise distance within each dataset\")\n",
    "plt.legend(fontsize='x-large')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for cat, d in dSS_dic.items():\n",
    "    sns.kdeplot(dSS_dic[cat], linewidth=3, label=cat)\n",
    "plt.title(\"Minimal pairwise distance within each dataset\")\n",
    "plt.legend(fontsize='x-large')\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, \"haplo_pairw_distrib_within.pdf\"), bbox_inches='tight', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "haplo = np.concatenate(list(full_datasets.values())).T  # orientation of scikit allele\n",
    "\n",
    "outFilePrefix = ''\n",
    "# if not ref in model_name_to_input_file.keys(): continue\n",
    "ref = 'Real'\n",
    "print(\"Computing AATS with ref \" + ref)\n",
    "AA, MINDIST = computeAAandDist(\n",
    "    pd.DataFrame(haplo.T),\n",
    "    extra_sample_info.label,\n",
    "    models_to_data.keys(),\n",
    "    refCateg=ref,\n",
    "    saveAllDist=True,\n",
    "    output_dir=output_dir,\n",
    "    outFilePrefix=outFilePrefix)\n",
    "\n",
    "# save AA and MINDIST pd.DataFrame to csv\n",
    "# np.array of all pariwise distances are saved as npz automatically when calling computeAAandDist with saveAllDist=True\n",
    "AA.to_csv(os.path.join(output_dir, f'AA_{ref}.csv.bz2'), index=None)\n",
    "MINDIST.to_csv(os.path.join(output_dir, f'MINDIST_{ref}.csv.bz2'), index=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Distribution WITHIN model_namesories\n",
    "W = pd.DataFrame(columns=['stat', 'statistic', 'label', 'comparaison'])\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "model_names = models_to_data.keys()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    subset = (np.load('{}/dist_{}_{}.npz'.format(output_dir, model_name, model_name)))['dist']\n",
    "    if model_name == 'Real':\n",
    "        subsetreal = subset\n",
    "    sns.kdeplot(subset, linewidth=3, label=model_name)\n",
    "\n",
    "    sc = scs.wasserstein_distance(subsetreal, subset)\n",
    "    new_row = pd.DataFrame(\n",
    "        {'stat': ['wasserstein'], 'statistic': [sc], 'label': [model_name], 'comparaison': ['within']})\n",
    "    W = pd.concat([W, new_row], ignore_index=True)\n",
    "\n",
    "plt.legend(loc='upper left', fontsize='x-large')\n",
    "plt.savefig(os.path.join(output_dir, \"distribution_haplotypic_pairwise_diff.jpg\"), bbox_inches='tight', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Distribution WITHIN model_namesories\n",
    "W = pd.DataFrame(columns=['stat', 'statistic', 'label', 'comparaison'])\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(1, 2, 1)\n",
    "model_names = models_to_data.keys()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    subset = (np.load('{}/dist_{}_{}.npz'.format(output_dir, model_name, model_name)))['dist']\n",
    "    if model_names == 'Real':\n",
    "        subsetreal = subset\n",
    "    sns.distplot(subset, hist=False, kde=True,\n",
    "                 kde_kws={'linewidth': 3},  #'bw':.02\n",
    "                 label='{} ({} identical pairs)'.format(model_names, (subset == 0).sum()))\n",
    "\n",
    "    sc = scs.wasserstein_distance(subsetreal, subset)\n",
    "    W = pd.concat([W, pd.DataFrame(\n",
    "        [{'stat': 'wasserstein', 'statistic': sc, 'pvalue': None, 'label': model_name, 'comparaison': 'between'}])],\n",
    "                  ignore_index=True)\n",
    "\n",
    "plt.title(\"Distribution of haplotypic pairwise difference within each dataset\")\n",
    "plt.legend()\n",
    "#plt.savefig(outDir+\"haplo_pairw_distrib_within_{}_simplify.pdf\".format(\"-\".join(categ)))\n",
    "subsetreal = None\n",
    "\n",
    "#### Distribution BETWEEN categories\n",
    "plt.subplot(1, 2, 2)\n",
    "model_names = models_to_data.keys()\n",
    "for i, model_name in enumerate(model_names):\n",
    "    subset = (np.load('{}/dist_{}_{}.npz'.format(output_dir, model_name, model_name)))['dist']\n",
    "    if model_name == 'Real':\n",
    "        subsetreal = subset\n",
    "    sns.distplot(subset, hist=False, kde=True,\n",
    "                 kde_kws={'linewidth': 3},  #'bw':.02\n",
    "                 label='{} vs {} ({} identical pairs)'.format(model_name, 'Real', (subset == 0).sum()))\n",
    "\n",
    "    sc = scs.wasserstein_distance(subsetreal, subset)\n",
    "    W = pd.concat([W, pd.DataFrame(\n",
    "        [{'stat': 'wasserstein', 'statistic': sc, 'pvalue': None, 'label': model_name, 'comparaison': 'between'}])])\n",
    "\n",
    "plt.title(\"Distribution of haplotypic pairwise difference between datasets\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, \"haplo_pairw_distrib.pdf\"))\n",
    "\n",
    "scores = pd.concat([W])\n",
    "\n",
    "print(W)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MINDIST.to_csv(os.path.join(output_dir, \"MINDIST.csv\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_score_distributions(df):\n",
    "    # Create a figure with three subplots, one for each score type\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 15))\n",
    "\n",
    "    # Set the column names for the score types\n",
    "    score_types = ['dTS', 'dST', 'dSS']\n",
    "\n",
    "    # Set the colors for each model\n",
    "    model_colors = sns.color_palette('Set1', n_colors=len(df['cat'].unique()))\n",
    "\n",
    "    # Create a dictionary to store the model names and their corresponding colors\n",
    "    model_color_dict = dict(zip(df['cat'].unique(), model_colors))\n",
    "\n",
    "    # Iterate over the score types\n",
    "    for i, score_type in enumerate(score_types):\n",
    "        # Select the data for the current score type\n",
    "        data = df[['cat', score_type]]\n",
    "\n",
    "        # Melt the data to transform it into long format\n",
    "        data_melted = data.explode(score_type).reset_index(drop=True)\n",
    "\n",
    "        # Plot the distribution for each model\n",
    "        for model in df['cat'].unique():\n",
    "            model_data = data_melted[data_melted['cat'] == model]\n",
    "            color = model_color_dict[model]\n",
    "\n",
    "            sns.histplot(data=model_data, x=score_type, element='step', stat='density',\n",
    "                         common_norm=False, fill=False, kde=True,\n",
    "                         ax=axes[i], color=color, label=model)\n",
    "\n",
    "        # Set plot title and labels\n",
    "        axes[i].set_title(f'Distribution of {score_type}')\n",
    "        axes[i].set_xlabel('Score')\n",
    "        axes[i].set_ylabel('Density')\n",
    "\n",
    "        # Set legend\n",
    "        axes[i].legend(title='Model', loc='upper right')\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_score_distributions(MINDIST)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_score_distributions(df, score_name):\n",
    "    flattened_df = df[['cat', score_name]].explode(score_name).reset_index(drop=True)\n",
    "\n",
    "    # Reorder the unique model names with 'Real' at the front\n",
    "    unique_models = list(flattened_df[\"cat\"].unique())\n",
    "    unique_models.remove('Real')\n",
    "    unique_models.append('Real')\n",
    "    color_palette['Real'] = 'black'\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Iterate over the reordered unique model names and plot the distribution for each\n",
    "    for model_name in unique_models:\n",
    "        if model_name == 'Real':\n",
    "            sns.kdeplot(data=flattened_df[flattened_df[\"cat\"] == model_name], x=score_name, label=model_name,\n",
    "                        fill=True, common_norm=False, alpha=0.6, color='black')\n",
    "        else:\n",
    "            sns.kdeplot(data=flattened_df[flattened_df[\"cat\"] == model_name], x=score_name, label=model_name,\n",
    "                        common_norm=False, alpha=1, linewidth=5)\n",
    "\n",
    "    plt.xlabel(score_name)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend(title=\"Model Name\", loc=\"upper right\")\n",
    "    plt.title(f\"Distribution of {score_name} by Model\")\n",
    "    plt.savefig(os.path.join(output_dir, score_name + \"_DISTRIBUTIONS.jpg\"))\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_score_distributions(MINDIST, 'dST')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_score_distributions(MINDIST, 'dTS')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_score_distributions(MINDIST, 'dSS')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W = pd.DataFrame(columns=['stat', 'statistic', 'label', 'comparaison'])\n",
    "for model_name in models_to_data.keys():\n",
    "    for method in ['dTS', 'dST', 'dSS']:\n",
    "        real = MINDIST[method][MINDIST.cat == 'Real'][0]\n",
    "        sc = scs.wasserstein_distance(real, MINDIST[method][MINDIST.cat == model_name].values[0])\n",
    "        new_row = pd.DataFrame({'stat': ['wasserstein'], 'statistic': [sc],\n",
    "                                'label': [model_name], 'comparaison': [method]})\n",
    "        W = pd.concat([W, new_row], ignore_index=True)\n",
    "scores = pd.concat([W])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = pd.concat([scores, W])\n",
    "scores.to_csv(os.path.join(output_dir, \"scores_pairwise_distances.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(1.5 * len(model_names), 6))\n",
    "\n",
    "sns.barplot(x='Cat', y='Value', hue='Variable', palette=sns.color_palette('colorblind'),\n",
    "            data=(AA.drop(columns=['PrivacyLoss', 'ref'], errors='ignore')).melt(id_vars='cat').rename(\n",
    "                columns=str.title))\n",
    "plt.axhline(0.5, color='black')\n",
    "if 'Real_test' in AA.cat.values:\n",
    "    plt.axhline(np.float(AA[AA.cat == 'Real_test'].AATS), color=sns.color_palette()[0], ls='--')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.title(\"Nearest Neighbor Adversarial Accuracy on training (AATS) and its components\")\n",
    "plt.savefig(os.path.join(output_dir, \"AATS_scores.pdf\"))\n",
    "\n",
    "Test = '_Test2'\n",
    "Train = ''  # means Training set is Real\n",
    "dfPL = plotPrivacyLoss(Train, Test, output_dir, color_palette, color_palette)\n",
    "\n",
    "Test = '_Test2'\n",
    "Train = '_Test1'\n",
    "dfPL = plotPrivacyLoss(Train, Test, output_dir, color_palette, color_palette)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def plot_3corr(x, y, keys, statname, col, ax=None):\n",
    "    \"\"\"\n",
    "    Plot for x versus y with regression scores and returns correlation coefficient\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array, scalar\n",
    "    y : array, scalar\n",
    "    statname : str\n",
    "        'Allele frequency' LD' or '3 point correlation' etc.\n",
    "    col : str, color code\n",
    "        color\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    lims = [np.min(x), np.max(x)]\n",
    "    r, _ = pearsonr(x, y)\n",
    "    if sm_loaded:\n",
    "        reg = sm.OLS(x, y).fit()\n",
    "    if ax is None:\n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "    if len(x) < 100:\n",
    "        alpha = 1\n",
    "    else:\n",
    "        alpha = .6\n",
    "    ax.plot(x, y, label=f\"{keys[1]}: cor={round(r, 2)}\", c=col, marker='o', lw=0, alpha=alpha)\n",
    "    ax.plot(lims, lims, ls='--', alpha=1, c='black')\n",
    "    ax.set_xlabel(f'{statname} in {keys[0]}')\n",
    "    ax.set_ylabel(f'{statname} in {keys[1]}')\n",
    "\n",
    "    return r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Points Correlation Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reduced_dataset = {'Real': full_datasets['Real'],\n",
    "                   'GAN 2019 Retrain': multiple_datasets['GAN 2019 Retrain'][0].to_numpy(),\n",
    "                   'Genome-AC-GAN By Continental Population':\n",
    "                       multiple_datasets['Genome-AC-GAN By Continental Population'][0].to_numpy()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_counts(haplosubset, points):\n",
    "    counts = np.unique(\n",
    "        np.apply_along_axis(\n",
    "            lambda x: ''.join(map(str, x[points])),\n",
    "            # lambda x: ''.join([str(x[p]) for p in points]),\n",
    "            0, haplosubset),\n",
    "        return_counts=True)\n",
    "    return (counts)\n",
    "\n",
    "\n",
    "def get_frequencies(counts):\n",
    "    l = len(counts[0][0])  # haplotype length\n",
    "    nind = np.sum(counts[1])\n",
    "    f = np.zeros(shape=[2] * l)\n",
    "    for i, allele in enumerate(counts[0]):\n",
    "        f[tuple(map(int, allele))] = counts[1][i] / nind\n",
    "    return f\n",
    "\n",
    "\n",
    "def three_points_cor(haplosubset, out='all'):\n",
    "    F = dict()\n",
    "    for points in [[0], [1], [2], [0, 1], [0, 2], [1, 2], [0, 1, 2]]:\n",
    "        strpoints = ''.join(map(str, points))\n",
    "        F[strpoints] = get_frequencies(\n",
    "            get_counts(haplosubset, points)\n",
    "        )\n",
    "\n",
    "    cors = [\n",
    "        F['012'][a, b, c] - F['01'][a, b] * F['2'][c] - F['12'][b, c] * F['0'][a] - F['02'][a, c] * F['1'][b] + 2 *\n",
    "        F['0'][a] * F['1'][b] * F['2'][c] for a, b, c in itertools.product(*[[0, 1]] * 3)]\n",
    "    if out == 'mean':\n",
    "        return (np.mean(cors))\n",
    "    if out == 'max':\n",
    "        return (np.max(np.abs(cors)))\n",
    "    if out == 'all':\n",
    "        return (cors)\n",
    "    return (ValueError(f\"out={out} not recognized\"))\n",
    "\n",
    "\n",
    "# def mult_three_point_cor(haplo, extra_sample_info, model_name, picked_three_points):\n",
    "#    return [three_points_cor(haplo[np.ix_(snps,extra_sample_info.label==model_name)], out='all') for snps in picked_three_points]\n",
    "\n",
    "# set the seed so that the same real individual are subsampled (when needed)\n",
    "# to ensure consistency of the scores when adding a new model or a new sumstat\n",
    "np.random.seed(3)\n",
    "random.seed(3)\n",
    "\n",
    "# Compute 3 point correlations results for different datasets and different distances between SNPs\n",
    "\n",
    "# pick distance between SNPs at which 3point corr will be computed\n",
    "# (defined in nb of snps)\n",
    "# a gap of -9 means that snp triplets are chosen completely at random (not predefined distance)\n",
    "# for each category we randomly pick 'nsamplesets' triplets\n",
    "\n",
    "# if datasets have different nb of snps, for convenience we will sample\n",
    "# slightly more at the beginning of the chunk\n",
    "\n",
    "gap_vec = [1, 4, 16, 64, 256, 512, 1024, -9]\n",
    "nsamplesets = 1000\n",
    "min_nsnp = min([dat.shape[1] for dat in reduced_dataset.values()])\n",
    "cors_meta = dict()\n",
    "for gap in gap_vec:\n",
    "    print(f'\\n gap={gap} SNPs', end=' ')\n",
    "    if gap < 0:\n",
    "        # pick 3 random snps\n",
    "        picked_three_points = [random.sample(range(min_nsnp), 3) for _ in range(nsamplesets)]\n",
    "    else:\n",
    "        try:\n",
    "            # pick 3 successive snps spearated by 'gap' SNPs\n",
    "            step = gap + 1\n",
    "            picked_three_points = [np.asarray(random.sample(range(min_nsnp - 2 * step), 1)) + [0, step, 2 * step]\n",
    "                                   for _\n",
    "                                   in range(nsamplesets)]\n",
    "        except:\n",
    "            continue  # if there were not enough SNPs for this gap\n",
    "    cors = dict()\n",
    "\n",
    "    for model_name in reduced_dataset.keys():\n",
    "        print(model_name, end=' ')\n",
    "        # cors[model_name]=[three_points_cor(haplo[np.ix_(snps,extra_sample_info.label==model_name)], out='all') for snps in picked_three_points]\n",
    "        cors[model_name] = [three_points_cor(reduced_dataset[model_name][:, snps].T, out='all') for snps in\n",
    "                            picked_three_points]\n",
    "\n",
    "    cors_meta[gap] = cors.copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(output_dir, \"3pointcorr.pkl\"), \"wb\") as outfile:\n",
    "    pickle.dump(cors_meta, outfile)\n",
    "\n",
    "plt.figure(figsize=(7 * len(cors_meta), 20))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for i, gap in enumerate((cors_meta).keys()):\n",
    "    ax = plt.subplot(2, int(np.ceil(len(cors_meta) / 2)), int(i) + 1)\n",
    "    cors = cors_meta[gap]\n",
    "    real = list(np.array(cors['Real']).flat)\n",
    "    lims = [np.min(real), np.max(real)]\n",
    "    model_to_corr = {}\n",
    "    for key, val in cors.items():\n",
    "        if key == 'Real': continue\n",
    "        val = list(np.array(val).flat)\n",
    "        corr = plot_3corr(x=real, y=val, keys=['Real', key],\n",
    "                          statname='Correlation', col=color_palette[key], ax=ax)\n",
    "        ax.set_ylabel(f'Correlation In Synthetic', fontsize=30)\n",
    "        ax.set_xlabel(f'Correlation In Real', fontsize=30)\n",
    "        ax.set_xlim((-.1, .1))\n",
    "        ax.set_ylim((-.1, .1))\n",
    "        model_to_corr[key] = corr\n",
    "\n",
    "    corr_size = str(gap) if gap > 0 else \"Random\"\n",
    "    title = [f\"3point Correlation By {corr_size} SNPs\"]\n",
    "    for model_name, corr_values in model_to_corr.items():\n",
    "        model_name_display = model_name.replace(\"Population\", \"\").replace(\"By \", \"\")\n",
    "        title.append(f\"{model_name}:{corr_values * 100: .1f}%\")\n",
    "    title = \"\\n\".join(title)\n",
    "    plt.title(title, fontsize=29, y=1.05, fontweight='bold')\n",
    "\n",
    "plt.savefig(os.path.join(output_dir, '3point_correlations_fixlim.jpg'), bbox_inches='tight', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def shuffle_test_dataset(test_dataset):\n",
    "    indices = np.arange(test_dataset[0].shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return (\n",
    "        test_dataset[0][indices],\n",
    "        np.array(test_dataset[1])[indices]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "def plot_pca_comparison(models):\n",
    "    rows_kmeans = []\n",
    "    for model_name, model_sequence in models.items():\n",
    "        # Skip 'Real' model\n",
    "        # if model_name == 'Real':\n",
    "        #     continue\n",
    "        print(f\"start model {model_name}\")\n",
    "        for i in range(50):\n",
    "            kmeans = MiniBatchKMeans(init='random', n_clusters=26, n_init=10, batch_size=512,\n",
    "                                     max_no_improvement=50)\n",
    "            kmeans.fit(model_sequence)\n",
    "            test_dataset_shuffled = shuffle_test_dataset(test_dataset)\n",
    "            test_predictions = kmeans.predict(test_dataset_shuffled[0])\n",
    "            ari_model = adjusted_rand_score(test_dataset_shuffled[1], test_predictions)\n",
    "            nmi_model = normalized_mutual_info_score(test_dataset_shuffled[1], test_predictions)\n",
    "\n",
    "            # Calculate silhouette score for real data\n",
    "            silhouette_score_real = silhouette_score(test_dataset_shuffled[0], test_predictions)\n",
    "            rows_kmeans.append({\"model_name\": model_name, \"ari_model\": ari_model, \"nmi_model\": nmi_model, \"silhouette_score_real\": silhouette_score_real})\n",
    "\n",
    "            # Print silhouette scores\n",
    "            print(\"Silhouette Score for Real Data:\", silhouette_score_real)\n",
    "\n",
    "    return pd.DataFrame(rows_kmeans)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_kmeans = plot_pca_comparison(full_datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"******* median *******\")\n",
    "print(df_kmeans.groupby('model_name')[\"ari_model\"].mean())\n",
    "\n",
    "print(\"\\n******* mean *******\")\n",
    "print(df_kmeans.groupby('model_name')[\"nmi_model\"].mean())\n",
    "\n",
    "\n",
    "print(\"\\n******* mean *******\")\n",
    "print(df_kmeans.groupby('model_name')[\"silhouette_score_real\"].mean())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
